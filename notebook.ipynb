{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Load Libs**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "# Native python libs\n",
    "import os\n",
    "import math\n",
    "from functools import lru_cache\n",
    "from datetime import datetime\n",
    "from typing import Any, Union, NoReturn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [],
   "source": [
    "# pip installed libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import sklearn\n",
    "import kerastuner_tensorboard_logger as kt_logger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Paths**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "BASE_PATH = f\"{os.path.abspath('')}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Kaggle**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [],
   "source": [
    "KAGGLE = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "KAGGLE_PATH = \"/kaggle\" if KAGGLE else f\"{BASE_PATH}\\\\kaggle\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "def submission_path_exists() -> str:\n",
    "    directory = f\"{KAGGLE_PATH}\\\\working\\\\{datetime.now().strftime('%d%m%Y')}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "        print(f\"Created new output directory for today at '{directory}'\")\n",
    "    return directory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [],
   "source": [
    "INPUT_PATH = f\"{KAGGLE_PATH}\\\\input\\\\goodreads-books-reviews-290312\"\n",
    "OUTPUT_PATH = submission_path_exists()\n",
    "SUBMISSION_PATH = f\"{OUTPUT_PATH}\\\\{datetime.now().strftime('%H%M%S')}_submission.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Tensorboard & General Monitoring**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "TENSORBOARD_LOGS_PATH = f\"{BASE_PATH}\\\\tensorboard_logs\"\n",
    "KERAS_TUNER_MONITOR_PATH = f\"{OUTPUT_PATH}\\\\keras_tuner_monitoring\"\n",
    "MONITOR_PATH = f\"{OUTPUT_PATH}\\\\monitoring.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "# Machine Learning tensorboard paths\n",
    "TENSORBOARD_LOGS_PATH_ML = f\"{TENSORBOARD_LOGS_PATH}\\\\ML\"\n",
    "LINEAR = f\"{TENSORBOARD_LOGS_PATH_ML}\\\\Linear\"\n",
    "MLP = f\"{TENSORBOARD_LOGS_PATH_ML}\\\\MLP\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "# Deep Learning tensorboard paths\n",
    "TENSORBOARD_LOGS_PATH_DL = f\"{TENSORBOARD_LOGS_PATH}\\\\DL\"\n",
    "CNN = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\CNN\"\n",
    "RESNET = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\ResNet\"\n",
    "RNN = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\RNN\"\n",
    "TRANSFORMER = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\Transformer\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\juanm\\\\OneDrive\\\\Bureau\\\\ESGI - Projets\\\\4IABD\\\\Projet Deep Learning\\\\tensorboard_logs'"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if path is good\n",
    "os.path.abspath(TENSORBOARD_LOGS_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hyperparameters**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "# Fix\n",
    "CLASSES = 6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [],
   "source": [
    "# Adjustable\n",
    "BATCH_SIZE = 1024  # Big batch size, small learning rate\n",
    "VOCAB_SIZE = 20000\n",
    "SEQUENCE_LENGTH = 256\n",
    "EMBEDDING_DIMS = 128\n",
    "EPOCHS = 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load Datasets**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.55 s\n",
      "Wall time: 6.37 s\n"
     ]
    }
   ],
   "source": [
    "% % time\n",
    "train_dataset = pd.read_csv(f\"{INPUT_PATH}\\\\goodreads_train.csv\",\n",
    "                            usecols=['review_text', 'rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(f\"{INPUT_PATH}\\\\goodreads_test.csv\",\n",
    "                           usecols=['review_text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**GPU/TPU MultiThreading Setup**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "    strategy = tf.distribute.experimental.TPUStrategy\n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print('Number of replicas:', strategy.num_replicas_in_sync)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "    gpus = tf.config.experimental.list_logical_devices(\"GPU\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on single GPU  /device:GPU:0\n",
      "Number of accelerators:  1\n"
     ]
    }
   ],
   "source": [
    "if tpu:\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu, )\n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "elif len(gpus) > 1:\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy([gpu.name for gpu in gpus])\n",
    "    print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
    "elif len(gpus) == 1:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print('Running on single GPU ', gpus[0].name)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print('Running on CPU')\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NLP**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [],
   "source": [
    "# Create a TextVectorization layer\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(standardize=None,\n",
    "                                                    output_sequence_length=SEQUENCE_LENGTH,\n",
    "                                                    output_mode='int')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16.5 s\n",
      "Wall time: 46.8 s\n"
     ]
    }
   ],
   "source": [
    "% % time\n",
    "with strategy.scope():\n",
    "    vectorize_layer.adapt(train_dataset['review_text'], batch_size=BATCH_SIZE * strategy.num_replicas_in_sync)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n '[UNK]',\n 'the',\n 'and',\n 'I',\n 'to',\n 'a',\n 'of',\n 'is',\n 'was',\n 'in',\n 'that',\n 'it',\n 'this',\n 'for',\n 'but',\n 'with',\n 'book',\n 'her',\n 'as',\n 'The',\n 'so',\n 'not',\n 'she',\n 'have',\n 'be',\n 'on',\n 'you',\n 'like',\n 'just',\n 'my',\n 'about',\n 'are',\n 'really',\n 'he',\n 'me',\n 'at',\n 'his',\n 'read',\n 'all',\n 'one',\n 'more',\n 'from',\n 'they',\n 'what',\n 'an',\n 'story',\n 'love',\n 'has',\n 'had',\n 'how',\n 'It',\n 'This',\n 'who',\n 'because',\n 'out',\n 'up',\n 'or',\n 'by',\n 'when',\n 'were',\n \"I'm\",\n 'would',\n 'their',\n 'much',\n 'some',\n 'get',\n \"didn't\",\n 'very',\n 'if',\n '-',\n 'there',\n 'characters',\n 'will',\n 'into',\n 'can',\n \"it's\",\n 'even',\n 'think',\n 'first',\n 'And',\n \"don't\",\n 'than',\n 'But',\n 'know',\n 'book.',\n 'also',\n 'been',\n 'it.',\n 'other',\n 'loved',\n 'only',\n 'good',\n 'reading',\n 'time',\n 'see',\n 'did',\n 'way',\n 'we',\n 'him',\n 'could',\n 'them',\n 'no',\n 'which',\n 'little',\n 'do',\n 'still',\n 'going',\n 'being',\n 'books',\n 'She',\n 'things',\n 'too',\n 'felt',\n \"It's\",\n 'made',\n 'feel',\n 'want',\n 'liked',\n 'series',\n 'never',\n 'book,',\n 'lot',\n 'character',\n 'people',\n 'make',\n 'after',\n 'where',\n 'two',\n 'then',\n 'bit',\n \"wasn't\",\n \"can't\",\n 'most',\n 'There',\n 'something',\n 'many',\n 'He',\n 'through',\n 'got',\n 'great',\n 'between',\n 'A',\n 'world',\n 'say',\n 'me.',\n 'am',\n 'thought',\n 'end',\n 'over',\n 'find',\n \"I've\",\n 'any',\n \"doesn't\",\n 'these',\n 'enjoyed',\n 'life',\n 'your',\n 'back',\n 'well',\n 'each',\n 'found',\n 'plot',\n 'while',\n 'go',\n 'new',\n 'those',\n 'writing',\n 'though',\n 'always',\n 'next',\n 'In',\n 'thing',\n 'kind',\n 'why',\n 'story.',\n 'actually',\n 'pretty',\n 'So',\n 'few',\n 'off',\n 'definitely',\n 'does',\n 'both',\n 'such',\n 'best',\n 'wanted',\n 'every',\n 'it,',\n 'makes',\n 'part',\n 'quite',\n 'If',\n 'whole',\n 'different',\n 'main',\n 'novel',\n 'everything',\n 'own',\n 'author',\n 'interesting',\n 'give',\n 'last',\n 'right',\n 'sure',\n 'better',\n 'before',\n 'same',\n 'its',\n \"she's\",\n \"that's\",\n 'enough',\n 'ever',\n 'take',\n 'romance',\n 'They',\n 'now',\n 'come',\n 'should',\n \"isn't\",\n 'What',\n 'hard',\n 'since',\n 'put',\n \"couldn't\",\n 'around',\n 'ending',\n 'review',\n 'relationship',\n 'down',\n 'another',\n 'read.',\n 'i',\n 'her.',\n 'without',\n 'long',\n 'You',\n 'series.',\n 'As',\n 'bad',\n 'need',\n \"he's\",\n 'until',\n 'real',\n '(hide',\n 'might',\n 'stars',\n 'keep',\n 'left',\n '(view',\n 'second',\n 'favorite',\n 'me,',\n 'anything',\n 'girl',\n 'them.',\n 'When',\n 'start',\n 'My',\n 'That',\n \"I'd\",\n 'point',\n 'started',\n 'family',\n 'trying',\n 'him.',\n 'may',\n 'wait',\n 'almost',\n 'probably',\n 'away',\n 'someone',\n 'story,',\n 'Not',\n 'getting',\n 'our',\n 'myself',\n 'years',\n 'times',\n \"I'll\",\n 'spoiler)]',\n 'nothing',\n 'fact',\n 'enjoy',\n 'help',\n 'especially',\n 'seems',\n 'completely',\n 'took',\n 'seemed',\n 'having',\n 'written',\n 'understand',\n 'characters.',\n 'looking',\n 'gets',\n 'fun',\n 'work',\n \"there's\",\n 'us',\n 'comes',\n 'together',\n 'one.',\n 'kept',\n 'heart',\n 'We',\n 'big',\n 'recommend',\n 'let',\n 'For',\n 'knew',\n 'characters,',\n 'everyone',\n 'able',\n \"you're\",\n 'person',\n 'man',\n 'finally',\n 'came',\n 'once',\n 'stories',\n 'tell',\n 'happy',\n 'that.',\n 'look',\n 'yet',\n 'old',\n 'went',\n 'full',\n 'All',\n 'young',\n 'least',\n 'past',\n 'perfect',\n 'happened',\n 'far',\n 'rather',\n 'time.',\n 'maybe',\n 'series,',\n 'idea',\n 'takes',\n 'set',\n 'One',\n 'pages',\n 'absolutely',\n 'believe',\n 'seem',\n 'three',\n 'hope',\n 'However,',\n 'place',\n 'friends',\n 'strong',\n 'herself',\n 'here',\n 'said',\n 'care',\n 'amazing',\n 'done',\n 'While',\n 'Her',\n 'already',\n 'wants',\n 'told',\n 'less',\n 'feeling',\n '&',\n 'beginning',\n 'high',\n 'must',\n 'that,',\n '5',\n 'wish',\n 'At',\n 'half',\n 'sense',\n 'totally',\n 'glad',\n 'beautiful',\n 'Even',\n '--',\n '.',\n 'life.',\n 'again',\n 'reason',\n 'her,',\n 'goes',\n 'easy',\n 'feels',\n 'end.',\n 'become',\n 'mind',\n 'nice',\n 'books.',\n 'YA',\n 'forward',\n 'well.',\n 'making',\n \"won't\",\n 'hate',\n 'couple',\n 'all.',\n 'reader',\n 'After',\n 'guy',\n 'truly',\n 'mean',\n 'parts',\n 'anyone',\n 'entire',\n \"She's\",\n 'more.',\n 'rest',\n 'day',\n 'gave',\n 'knows',\n 'school',\n 'live',\n 'year',\n 'friend',\n \"wouldn't\",\n 'way.',\n 'used',\n 'short',\n 'action',\n 'sort',\n 'feelings',\n 'sex',\n 'try',\n 'coming',\n 'read,',\n 'scenes',\n 'this.',\n 'along',\n 'out.',\n 'happens',\n \"There's\",\n 'side',\n 'fantasy',\n '(and',\n 'job',\n 'write',\n 'throughout',\n 'stop',\n 'woman',\n 'guess',\n \"He's\",\n \"they're\",\n 'seeing',\n 'fan',\n 'given',\n 'thinking',\n '4',\n 'mystery',\n 'lost',\n 'exactly',\n 'happen',\n 'else',\n 'all,',\n 'true',\n 'boy',\n 'finished',\n 'stars.',\n 'sometimes',\n '3',\n 'up.',\n 'him,',\n 'character.',\n 'novel.',\n 'To',\n 'time,',\n 'fall',\n 'Just',\n 'mother',\n '**',\n 'doing',\n 'worth',\n 'remember',\n 'sweet',\n 'books,',\n 'although',\n 'instead',\n 'lives',\n 'learn',\n 'readers',\n 'father',\n 'ended',\n 'change',\n 'dark',\n 'again.',\n 'needed',\n 'course',\n 'Then',\n 'human',\n 'during',\n 'Also,',\n 'honest',\n 'saw',\n 'head',\n 'end,',\n 'much.',\n 'this,',\n 'Maybe',\n 'good.',\n 'too.',\n 'is,',\n 'seen',\n 'though,',\n 'often',\n 'against',\n 'His',\n 'page',\n 'pick',\n 'issues',\n 'moments',\n 'one,',\n 'others',\n 'starts',\n 'How',\n 'emotional',\n 'them,',\n 'wonderful',\n 'style',\n 'words',\n 'on.',\n 'giving',\n 'use',\n 'previous',\n 'despite',\n 'slow',\n 'world.',\n 'Now',\n 'scene',\n 'character,',\n 'magic',\n 'needs',\n 'problem',\n 'finds',\n 'important',\n \"haven't\",\n \"That's\",\n '\"I',\n 'finish',\n 'huge',\n 'leave',\n 'himself',\n 'spoiler)[',\n 'cannot',\n '2',\n 'turn',\n 'show',\n 'supposed',\n 'turned',\n 'No',\n 'third',\n 'female',\n 'funny',\n 'reviews',\n 'sad',\n 'is.',\n 'talk',\n 'THE',\n 'certain',\n 'women',\n 'Like',\n 'fell',\n '3.5',\n 'wrong',\n 'small',\n 'well,',\n 'you.',\n 'hot',\n 'With',\n 'Overall,',\n 'expect',\n 'towards',\n 'Some',\n 'movie',\n 'became',\n 'novel,',\n 'moment',\n 'simply',\n 'life,',\n 'behind',\n 'together.',\n 'Book',\n 'star',\n 'On',\n '(I',\n 'home',\n 'several',\n 'interested',\n 'living',\n 'Because',\n 'surprised',\n 'down.',\n 'matter',\n 'love.',\n 'excited',\n 'decided',\n 'deal',\n 'turns',\n 'expected',\n 'future',\n 'super',\n 'eyes',\n 'unique',\n 'death',\n 'mostly',\n 'parents',\n 'events',\n ':)',\n 'said,',\n 'figure',\n 'middle',\n \"aren't\",\n 'So,',\n 'heroine',\n 'usually',\n 'picked',\n 'certainly',\n 'it!',\n 'girls',\n 'name',\n 'saying',\n 'there.',\n 'close',\n 'other.',\n 'either',\n 'later',\n 'meet',\n 'did.',\n 'though.',\n 'difficult',\n 'final',\n 'book!',\n 'chapters',\n 'highly',\n 'soon',\n 'again,',\n 'face',\n 'becomes',\n 'under',\n 'here.',\n 'ends',\n 'you,',\n 'honestly',\n 'extremely',\n 'mean,',\n 'way,',\n 'continue',\n 'romantic',\n 'crazy',\n 'single',\n 'ending.',\n 'Why',\n 'copy',\n 'review.',\n 'chapter',\n 'now.',\n 'fast',\n 'gives',\n 'experience',\n 'novels',\n 'awesome',\n 'heard',\n 'taking',\n 'taken',\n 'overall',\n 'be.',\n 'stand',\n 'stuff',\n '4.5',\n 'kill',\n 'within',\n 'love,',\n 'stay',\n 'men',\n 'called',\n 'means',\n 'wanting',\n 'interest',\n 'better.',\n 'expecting',\n 'line',\n 'meets',\n 'cover',\n 'particularly',\n 'brother',\n 'in.',\n 'original',\n 'course,',\n 'waiting',\n 'sister',\n 'quickly',\n 'across',\n 'incredibly',\n 'quick',\n 'save',\n 'type',\n 'light',\n 'Of',\n 'spoiler',\n 'history',\n 'realize',\n 'Although',\n 'move',\n 'good,',\n 'development',\n 'Oh',\n 'world,',\n 'four',\n 'admit',\n 'brought',\n 'basically',\n 'Well,',\n 'adult',\n 'case',\n 'up,',\n 'loves',\n 'chance',\n 'setting',\n 'twists',\n 'play',\n 'out,',\n 'whether',\n 'hoping',\n 'power',\n 'fight',\n 'five',\n 'disappointed',\n 'enjoyable',\n 'easily',\n 'Will',\n 'night',\n 'cute',\n 'talking',\n 'fantastic',\n 'order',\n 'works',\n 'tale',\n 'tried',\n 'Yes,',\n 'clear',\n 'Review',\n 'twist',\n 'First',\n 'thoughts',\n 'New',\n \"what's\",\n 'major',\n 'lack',\n 'weird',\n 'Harry',\n 'hero',\n 'itself',\n 'hated',\n 'ones',\n 'shows',\n 'fiction',\n 'personal',\n 'building',\n '...',\n 'kids',\n 'word',\n 'finding',\n 'historical',\n 'actual',\n 'favourite',\n 'days',\n 'telling',\n 'keeps',\n 'hell',\n 'romance.',\n 'Read',\n 'follow',\n 'emotions',\n 'knowing',\n 'journey',\n 'on,',\n 'ways',\n \"you'll\",\n 'was.',\n 'times.',\n 'top',\n 'romance,',\n 'based',\n 'group',\n 'male',\n 'questions',\n 'lots',\n 'bring',\n \"weren't\",\n 'These',\n 'Their',\n 'problems',\n 'to.',\n 'call',\n 'reading.',\n 'interesting.',\n 'sexy',\n 'complete',\n 'about.',\n 'exchange',\n 'break',\n 'know,',\n 'worked',\n 'times,',\n 'authors',\n 'spent',\n 'voice',\n 'points',\n 'known',\n 'mention',\n 'tells',\n 'Or',\n 'literally',\n 'town',\n 'From',\n 'friendship',\n 'age',\n 'similar',\n 'says',\n 'trust',\n 'forced',\n 'due',\n 'evil',\n 'watching',\n 'deep',\n 'except',\n 'focus',\n 'annoying',\n 'relationships',\n 'hold',\n 'early',\n 'somewhat',\n 'sexual',\n 'details',\n 'themselves',\n 'run',\n 'guys',\n 'Another',\n 'children',\n 'SO',\n 'met',\n 'inside',\n 'rating',\n 'magical',\n 'wonder',\n 'meant',\n 'however,',\n 'working',\n 'connection',\n 'amount',\n 'seriously',\n 'now,',\n 'free',\n 'But,',\n 'longer',\n 'plot.',\n 'view',\n \"Don't\",\n 'realistic',\n 'war',\n 'secret',\n 'thinks',\n 'changed',\n 'killed',\n 'drama',\n 'situation',\n 'beyond',\n 'elements',\n 'open',\n 'fully',\n 'say,',\n 'thing.',\n 'reminded',\n 'fact,',\n 'obvious',\n 'grow',\n 'attention',\n 'Love',\n 'AND',\n '\"The',\n 'appreciate',\n 'starting',\n 'tries',\n 'slightly',\n 'away.',\n 'alert',\n 'immediately',\n 'grew',\n 'imagine',\n 'lead',\n '(which',\n \"you've\",\n 'people.',\n 'received',\n 'hands',\n 'hit',\n 'typical',\n 'added',\n 'loving',\n 'first,',\n 'missing',\n 'strange',\n 'premise',\n 'boring',\n 'plot,',\n 'dead',\n 'fit',\n 'serious',\n 'really,',\n 'developed',\n 'Is',\n 'there,',\n 'somehow',\n 'filled',\n '(or',\n 'created',\n 'issue',\n 'Stars',\n 'not.',\n 'entirely',\n 'with.',\n 'version',\n 'child',\n 'mentioned',\n 'powerful',\n 'cool',\n 'Ms.',\n 'present',\n 'Which',\n 'constantly',\n 'hurt',\n 'complex',\n 'upon',\n 'special',\n 'was,',\n 'Though',\n 'ready',\n 'slowly',\n 'information',\n 'sequel',\n 'King',\n 'entertaining',\n 'annoyed',\n 'nearly',\n 'interesting,',\n 'concept',\n 'together,',\n 'happening',\n 'house',\n 'clearly',\n 'aspect',\n 'storyline',\n 'do.',\n 'normal',\n 'realized',\n 'wrote',\n 'alone',\n 'add',\n 'leaves',\n 'falling',\n 'Loved',\n 'whose',\n 'begins',\n 'perhaps',\n 'kinda',\n 'hear',\n 'Once',\n '*',\n '(the',\n 'mysterious',\n 'stupid',\n 'older',\n 'Kate',\n 'heart.',\n 'society',\n 'excellent',\n 'drawn',\n 'great.',\n 'question',\n 'okay',\n 'gone',\n 'An',\n 'writes',\n 'here,',\n 'fairly',\n 'Also',\n 'willing',\n 'amazing.',\n 'Overall',\n 'narrative',\n 'near',\n 'Every',\n 'begin',\n 'things.',\n 'family.',\n ...]"
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [],
   "source": [
    "def vectorize_text(text: Any, label: Any) -> Any:\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Creating Dataset For Models**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = sklearn.model_selection.train_test_split(train_dataset, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [],
   "source": [
    "def dataset_from_raw_data(x: np.ndarray, y: np.ndarray, batch_size: int = BATCH_SIZE) -> Any:\n",
    "    # Create dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)\n",
    "    # Vectorize\n",
    "    dataset = dataset.map(vectorize_text)\n",
    "    print(dataset.element_spec)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset_from_raw_data(train_dataset['review_text'], train_dataset['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = dataset_from_raw_data(validation_dataset['review_text'], validation_dataset['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Linear**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "def linear(hp: kt.HyperParameters) -> tf.keras.Sequential:\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(CLASSES, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**MLP**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "def mlp(hp: kt.HyperParameters) -> tf.keras.Sequential:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "    hp_units_0 = hp.Int('units_0', min_value=32, max_value=512, step=32)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units_0, activation='relu'))\n",
    "    hp_units_1 = hp.Int('units_1', min_value=32, max_value=512, step=32)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units_1, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(CLASSES, activation='sigmoid'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**CNN**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [],
   "source": [
    "def cnn(hp: kt.HyperParameters) -> tf.keras.Sequential:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int32))\n",
    "    model.add(tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS))\n",
    "    model.add(tf.keras.layers.Reshape((math.isqrt(SEQUENCE_LENGTH), math.isqrt(SEQUENCE_LENGTH), -1),\n",
    "                                      input_shape=(None, SEQUENCE_LENGTH)))\n",
    "\n",
    "    # Conv & pooling tf.keras.layers\n",
    "    hp_filters_0 = hp.Int('filters_0', min_value=8, max_value=32, step=8)\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_0, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_0, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    hp_filters_1 = hp.Int('filters_1', min_value=16, max_value=64, step=16)\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_1, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_1, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    hp_filters_2 = hp.Int('filters_2', min_value=32, max_value=128, step=32)\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_2, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_2, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    hp_filters_3 = hp.Int('filters_3', min_value=64, max_value=256, step=64)\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_3, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_3, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "    # Fully connected tf.keras.layers\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    hp_units_0 = hp.Int('units_0', min_value=64, max_value=256, step=64)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units_0, activation='relu'))\n",
    "    hp_units_1 = hp.Int('units_1', min_value=32, max_value=128, step=32)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units_1, activation='relu'))\n",
    "    hp_units_2 = hp.Int('units_2', min_value=16, max_value=64, step=16)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units_2, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(CLASSES, activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**ResNet**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def residual_module(data,\n",
    "                    filters,\n",
    "                    stride,\n",
    "                    reduce=False,\n",
    "                    reg=0.0001,\n",
    "                    bn_eps=2e-5,\n",
    "                    bn_momentum=0.9):\n",
    "    bn_1 = tf.keras.layers.BatchNormalization(axis=-1,\n",
    "                                              epsilon=bn_eps,\n",
    "                                              momentum=bn_momentum)(data)\n",
    "    act_1 = tf.keras.layers.ReLU()(bn_1)\n",
    "    conv_1 = tf.keras.layers.Conv2D(filters=int(filters / 4.),\n",
    "                                    kernel_size=(1, 1),\n",
    "                                    use_bias=False,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(reg))(act_1)\n",
    "    bn_2 = tf.keras.layers.BatchNormalization(axis=-1,\n",
    "                                              epsilon=bn_eps,\n",
    "                                              momentum=bn_momentum)(conv_1)\n",
    "    act_2 = tf.keras.layers.ReLU()(bn_2)\n",
    "    conv_2 = tf.keras.layers.Conv2D(filters=int(filters / 4.),\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    strides=stride,\n",
    "                                    padding='same',\n",
    "                                    use_bias=False,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(reg))(act_2)\n",
    "    bn_3 = tf.keras.layers.BatchNormalization(axis=-1,\n",
    "                                              epsilon=bn_eps,\n",
    "                                              momentum=bn_momentum)(conv_2)\n",
    "    act_3 = tf.keras.layers.ReLU()(bn_3)\n",
    "    conv_3 = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                    kernel_size=(1, 1),\n",
    "                                    use_bias=False,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(reg))(act_3)\n",
    "\n",
    "    if reduce:\n",
    "        shortcut = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                          kernel_size=(1, 1),\n",
    "                                          strides=stride,\n",
    "                                          use_bias=False,\n",
    "                                          kernel_regularizer=tf.keras.regularizers.l2(reg))(act_1)\n",
    "\n",
    "    x = tf.keras.layers.Add()([conv_3, shortcut])\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_resnet(stages,\n",
    "                 filters,\n",
    "                 reg,\n",
    "                 bn_eps,\n",
    "                 bn_momentum):\n",
    "    inputs = tf.keras.Input(shape=(SEQUENCE_LENGTH,))\n",
    "    x = inputs\n",
    "    x = tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS)(x)\n",
    "    x = tf.keras.layers.Reshape((SEQUENCE_LENGTH, 1))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1,\n",
    "                                           epsilon=bn_eps,\n",
    "                                           momentum=bn_momentum)(inputs)\n",
    "    x = tf.keras.layers.Conv2D(filters[0], (3, 3),\n",
    "                               use_bias=False,\n",
    "                               padding='same',\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(reg))(x)\n",
    "    for i in range(len(stages)):\n",
    "        stride = (1, 1) if i == 0 else (2, 2)\n",
    "        x = residual_module(data=x, filters=filters[i + 1], stride=stride,\n",
    "                            reduce=True, bn_eps=bn_eps, bn_momentum=bn_momentum)\n",
    "        for j in range(stages[i] - 1):\n",
    "            x = residual_module(data=x,\n",
    "                                filters=filters[i + 1],\n",
    "                                stride=(1, 1),\n",
    "                                bn_eps=bn_eps,\n",
    "                                bn_momentum=bn_momentum)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1,\n",
    "                                           epsilon=bn_eps,\n",
    "                                           momentum=bn_momentum)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.AveragePooling2D((8, 8))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(CLASSES, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(reg))(x)\n",
    "    return tf.keras.Model(inputs, x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [],
   "source": [
    "def resnet(hp: kt.HyperParameters) -> tf.keras.Sequential:\n",
    "    model = build_resnet(stages=hp.Choice('stages', values=[[3, 4, 6, 3], [2, 2, 2, 2], [1, 1, 1, 1]]),\n",
    "                         filters=hp.Choice('filters', values=[[64, 64, 128, 256, 512], [32, 32, 64, 128, 256]]),\n",
    "                         reg=hp.Float('reg', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3),\n",
    "                         bn_eps=hp.Float('bn_eps', min_value=1e-5, max_value=1e-3, sampling='LOG', default=2e-5),\n",
    "                         bn_momentum=hp.Float('bn_momentum', min_value=0.8, max_value=0.99, sampling='LOG', default=0.9))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**RNN**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "def rnn(hp: kt.HyperParameters) -> tf.keras.Sequential:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS))\n",
    "    hp_units_0 = hp.Int('units_0', min_value=32, max_value=512, step=32)\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hp_units_0, dropout=hp_dropout,\n",
    "                                                                 recurrent_dropout=hp_dropout, return_sequences=True)))\n",
    "    hp_units_1 = hp.Int('units_1', min_value=32, max_value=512, step=32)\n",
    "    model.add(tf.keras.layers.Dense(hp_units_1, activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(CLASSES, activation='sigmoid'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Simpler RNN**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [],
   "source": [
    "def simple_rnn(hp: kt.HyperParameters) -> tf.keras.Sequential:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int32))\n",
    "    model.add(tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS))\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(tf.keras.layers.SimpleRNN(hp_units))\n",
    "    model.add(tf.keras.layers.Dense(CLASSES, activation='sigmoid'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Transformer**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = tf.keras.layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = tf.keras.layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [],
   "source": [
    "def build_model(head_size: int, num_heads: int, ff_dim: int, num_transformer_blocks: int, mlp_units: list[int], dropout: float, mlp_dropout: float):\n",
    "    inputs = tf.keras.Input(shape=(SEQUENCE_LENGTH,))\n",
    "    x = inputs\n",
    "    x = tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS)(x)\n",
    "    x = tf.keras.layers.Reshape((SEQUENCE_LENGTH, 1))(x)\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = tf.keras.layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = tf.keras.layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = tf.keras.layers.Dense(CLASSES, activation=\"softmax\")(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [],
   "source": [
    "def transformer(hp: kt.HyperParameters) -> tf.keras.Sequential:\n",
    "    model = build_model(head_size=hp.Int('head_size', min_value=32, max_value=512, step=32),\n",
    "                        num_heads=hp.Int('num_heads', min_value=2, max_value=8, step=1),\n",
    "                        ff_dim=hp.Int('ff_dim', min_value=32, max_value=512, step=32),\n",
    "                        num_transformer_blocks=hp.Int('num_transformer_blocks', min_value=1, max_value=4, step=1),\n",
    "                        mlp_units=[hp.Int('mlp_units', min_value=32, max_value=512, step=32)],\n",
    "                        mlp_dropout=hp.Float('mlp_dropout', min_value=0.0, max_value=0.5, step=0.1),\n",
    "                        dropout=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Utilitary For Monitoring**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [],
   "source": [
    "def tensorboard_logs(model_name: str) -> tf.keras.callbacks.TensorBoard:\n",
    "    return tf.keras.callbacks.TensorBoard(f\"{globals()[model_name.upper()]}\"\n",
    "                                          f\"_BS_{BATCH_SIZE}\"\n",
    "                                          f\"_MAXFEAT_{VOCAB_SIZE}\"\n",
    "                                          f\"_EMBEDDING_{EMBEDDING_DIMS}\"\n",
    "                                          f\"_SEQLEN_{SEQUENCE_LENGTH}\"\n",
    "                                          f\"_EPOCHS_{EPOCHS}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training & Hyperparameter Optimization**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [],
   "source": [
    "def optimizer_choice(model: tf.keras.Sequential, model_name: str, optimizer: str):\n",
    "    if optimizer == \"RandomSearch\":\n",
    "        tuner = kt.RandomSearch(model,\n",
    "                                objective=kt.Objective('val_accuracy', direction='max'),\n",
    "                                max_trials=EPOCHS,\n",
    "                                overwrite=True,\n",
    "                                project_name=f\"{OUTPUT_PATH}\\\\{model_name}_tuner\",\n",
    "                                directory=f\"{KERAS_TUNER_MONITOR_PATH}_{model_name}\")\n",
    "    elif optimizer == \"BayesianOptimization\":\n",
    "        tuner = kt.BayesianOptimization(model,\n",
    "                                        objective=kt.Objective('val_accuracy', direction='max'),\n",
    "                                        max_trials=EPOCHS,\n",
    "                                        overwrite=True,\n",
    "                                        project_name=f\"{OUTPUT_PATH}\\\\{model_name}_tuner\",\n",
    "                                        directory=f\"{KERAS_TUNER_MONITOR_PATH}_{model_name}\")\n",
    "    elif optimizer == \"Hyperband\":\n",
    "        tuner = kt.Hyperband(model,\n",
    "                             objective=kt.Objective('val_accuracy', direction='max'),\n",
    "                             max_epochs=EPOCHS,\n",
    "                             overwrite=True,\n",
    "                             project_name=f\"{OUTPUT_PATH}\\\\{model_name}_tuner\",\n",
    "                             logger=kt_logger.TensorBoardLogger(metrics=['val_accuracy'],\n",
    "                                                                logdir=f\"{KERAS_TUNER_MONITOR_PATH}_{model_name}\"))\n",
    "    else:\n",
    "        raise ValueError(\"optimizer_choice must be 0, 1 or 2\")\n",
    "\n",
    "    return tuner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "def hp_optimization_and_training(model: Any, optimizer: str = \"Hyperband\") -> NoReturn:\n",
    "    model_name = model.__name__\n",
    "    with strategy.scope():\n",
    "        tuner = optimizer_choice(model, model_name, optimizer=optimizer)\n",
    "\n",
    "        # Search for best hyperparameters\n",
    "        tuner.search(train_dataset,\n",
    "                     epochs=EPOCHS,\n",
    "                     validation_data=validation_dataset,\n",
    "                     callbacks=[stop_early,\n",
    "                                tensorboard_logs(model_name)])\n",
    "        # Get the optimal hyperparameters\n",
    "        best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "        print(best_hps)\n",
    "\n",
    "        # Build model with optimal hyperparameters\n",
    "        model = tuner.hypermodel.build(best_hps)\n",
    "        history = model.fit(train_dataset,\n",
    "                            epochs=EPOCHS,\n",
    "                            validation_data=validation_dataset,\n",
    "                            callbacks=[stop_early,\n",
    "                                       tensorboard_logs(model_name)])\n",
    "        val_acc_per_epoch = history.history['val_accuracy']\n",
    "        best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "        print(f\"best_epoch : {best_epoch}\")\n",
    "\n",
    "        hypermodel = tuner.hypermodel.build(best_hps)\n",
    "        # Retrain the model\n",
    "        hypermodel.fit(train_dataset,\n",
    "                       epochs=best_epoch,\n",
    "                       callbacks=[stop_early,\n",
    "                                  tensorboard_logs(model_name)])\n",
    "\n",
    "        eval_result = hypermodel.evaluate(validation_dataset)\n",
    "        for index, column in enumerate(['loss', 'accuracy']):\n",
    "            print(f\"{column} : {eval_result[index]}\")\n",
    "\n",
    "        hypermodel.save(f\"{OUTPUT_PATH}\\\\\"\n",
    "                        f\"{model_name}\"\n",
    "                        f\"_loss_{eval_result[0]}\"\n",
    "                        f\"_acc_{eval_result[1]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hp_optimization_and_training(linear)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 05m 07s]\n",
      "val_accuracy: 0.5458278059959412\n",
      "\n",
      "Best val_accuracy So Far: 0.5479888916015625\n",
      "Total elapsed time: 14h 53m 57s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "optimal_learning_rate : 0.01\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'units does not exist.'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [320]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mhp_optimization_and_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmlp\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [317]\u001B[0m, in \u001B[0;36mhp_optimization_and_training\u001B[1;34m(model, optimizer)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimal_learning_rate : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_hps\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_name \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 16\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimal_num_units : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_hps\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124munits\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Build model with optimal hyperparameters\u001B[39;00m\n\u001B[0;32m     19\u001B[0m model \u001B[38;5;241m=\u001B[39m tuner\u001B[38;5;241m.\u001B[39mhypermodel\u001B[38;5;241m.\u001B[39mbuild(best_hps)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\keras_tuner\\engine\\hyperparameters\\hyperparameters.py:236\u001B[0m, in \u001B[0;36mHyperParameters.get\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is currently inactive.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not exist.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'units does not exist.'"
     ]
    }
   ],
   "source": [
    "hp_optimization_and_training(mlp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hp_optimization_and_training(cnn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m(rnn)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "hp_optimization_and_training(simple_rnn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hp_optimization_and_training(transformer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# In case of multiple models training\n",
    "for model in [linear, mlp, cnn, simple_rnn, transformer]:\n",
    "    hp_optimization_and_training(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Evaluation**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linear_loss_1.0978895425796509_acc_0.5394444465637207', 'mlp_loss_1.073839545249939_acc_0.5354999899864197', 'linear_loss_1.113369345664978_acc_0.5319499969482422', 'cnn_loss_1.1353473663330078_acc_0.5252388715744019']\n",
      "['mlp_loss_1.073839545249939_acc_0.5354999899864197', 'linear_loss_1.0978895425796509_acc_0.5394444465637207', 'linear_loss_1.113369345664978_acc_0.5319499969482422', 'cnn_loss_1.1353473663330078_acc_0.5252388715744019']\n"
     ]
    }
   ],
   "source": [
    "models = [dir for root, dirs, files in os.walk(f'{KAGGLE_PATH}/working') for dir in dirs if dir.__contains__(\"acc\")]\n",
    "sort_models_per_acc = sorted(models, key=lambda x: float(x[x.find('_acc_') + 5:]), reverse=True)\n",
    "sort_models_per_loss = sorted(models, key=lambda x: float(x[x.find('_loss_') + 6:x.find('_acc_')]))\n",
    "print(sort_models_per_acc)\n",
    "print(sort_models_per_loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(f\"{KAGGLE_PATH}/working/{sort_models_per_acc[0]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Submission**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['review_id'] = [data.decode(\"utf-8\") for data in test_dataset['review_id']]\n",
    "submission['rating'] = best_model.predict(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [59]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43msubmission\u001B[49m\u001B[38;5;241m.\u001B[39mto_csv(OUTPUT_PATH, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCSV registered at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mOUTPUT_PATH\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'submission' is not defined"
     ]
    }
   ],
   "source": [
    "submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "print(f\"Submission registered at {SUBMISSION_PATH}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
