{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df64540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import string\n",
    "\n",
    "print(tf.__version__)\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba293d91",
   "metadata": {},
   "source": [
    "Obtenir les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a420c3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rating  reading_time  localisation\n",
      "899995       5           4.0          -700\n",
      "899996       5           NaN          -700\n",
      "899997       0           NaN          -700\n",
      "899998       4           4.0          -700\n",
      "899999       5           1.0          -700\n"
     ]
    }
   ],
   "source": [
    "url_train_with_reading_time_NaN = 'src/data/initial/goodreads_train_with_reading_time_NaN.csv'\n",
    "url_train_with_reading_time = 'src/data/initial/goodreads_train_with_reading_time.csv'\n",
    "url_train_not_reading_time = 'src/data/initial/goodreads_train_not_reading_time.csv'\n",
    "\n",
    "raw_dataset = pd.read_csv(url_train_with_reading_time_NaN, \n",
    "                          na_values='?', sep=',')\n",
    "\n",
    "# Solution 1 / ne marche pas\n",
    "# raw_dataset = raw_dataset.replace('a','1', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('b','2', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('c','3', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('d','4', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('e','5', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('f','6', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('g','7', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('h','8', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('i','9', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('j','10', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('k','11', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('l','12', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('m','13', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('n','14', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('o','15', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('p','16', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('q','17', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('r','18', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('s','19', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('t','20', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('u','21', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('v','22', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('w','23', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('x','24', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('y','25', regex=True)\n",
    "# raw_dataset = raw_dataset.replace('z','26', regex=True)\n",
    "\n",
    "# Solution 2 / ne marche pas\n",
    "# for char in list(string.ascii_lowercase):\n",
    "#     print(char, type(ord(char)))\n",
    "#     raw_dataset = raw_dataset.replace(char, ord(char), regex=True)\n",
    "#     print(raw_dataset.tail())\n",
    "# raw_dataset = raw_dataset.astype(float)\n",
    "\n",
    "# Solution 3 / marche mais pas sue tout le data set\n",
    "# df_mask=raw_dataset['rating']==2\n",
    "# filtered_df = raw_dataset[df_mask]\n",
    "\n",
    "# raw_dataset2 = pd.get_dummies(filtered_df['review_id'])\n",
    "# print(raw_dataset2.tail())\n",
    "\n",
    "# Solution 4 / marche mais pas les id les book\n",
    "raw_dataset = raw_dataset.drop(['review_id'], axis=1) \n",
    "dataset = raw_dataset.copy()\n",
    "print(dataset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533ce85",
   "metadata": {},
   "source": [
    "Nettoyer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fcc4d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rating  reading_time  localisation\n",
      "899993       4           4.0          -700\n",
      "899994       5           2.0          -700\n",
      "899995       5           4.0          -700\n",
      "899998       4           4.0          -700\n",
      "899999       5           1.0          -700\n"
     ]
    }
   ],
   "source": [
    "# suppretion des valeurs vides\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "print(dataset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b0c17",
   "metadata": {},
   "source": [
    "Diviser les données en train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c474474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215745ee",
   "metadata": {},
   "source": [
    "Séparer la valeur rechercher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "024b5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('rating')\n",
    "test_labels = test_features.pop('rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a18ce84",
   "metadata": {},
   "source": [
    "Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1639e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  11.507, -732.904]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "normalizer.adapt(np.array(train_features)) # .values.astype(np.float32)\n",
    "\n",
    "normalizer.mean.numpy()\n",
    "\n",
    "# first = np.array(train_features[:1])\n",
    "# with np.printoptions(precision=2, suppress=True):\n",
    "#   print('First example:', first)\n",
    "#   print()\n",
    "#   print('Normalized:', normalizer(first).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51129288",
   "metadata": {},
   "source": [
    "Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a68cc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage entrainement \n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce78c262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 2)                5         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8\n",
      "Trainable params: 3\n",
      "Non-trainable params: 5\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Modele\n",
    "linear_model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1)\n",
    "])\n",
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c8701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomcareghi\\.conda\\envs\\DeepLearning\\lib\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12310/12310 [==============================] - 62s 5ms/step - loss: 0.8354 - val_loss: 0.8297\n",
      "Epoch 2/10\n",
      "12310/12310 [==============================] - 53s 4ms/step - loss: 0.8315 - val_loss: 0.8402\n",
      "Epoch 3/10\n",
      "12310/12310 [==============================] - 55s 4ms/step - loss: 0.8318 - val_loss: 0.8184\n",
      "Epoch 4/10\n",
      "12310/12310 [==============================] - 54s 4ms/step - loss: 0.8318 - val_loss: 0.8859\n",
      "Epoch 5/10\n",
      "12310/12310 [==============================] - 56s 5ms/step - loss: 0.8319 - val_loss: 0.8344\n",
      "Epoch 6/10\n",
      "12310/12310 [==============================] - 52s 4ms/step - loss: 0.8314 - val_loss: 0.8177\n",
      "Epoch 7/10\n",
      "12310/12310 [==============================] - 54s 4ms/step - loss: 0.8314 - val_loss: 0.8445\n",
      "Epoch 8/10\n",
      "12310/12310 [==============================] - 55s 4ms/step - loss: 0.8320 - val_loss: 0.8304\n",
      "Epoch 9/10\n",
      "12310/12310 [==============================] - 53s 4ms/step - loss: 0.8321 - val_loss: 0.8263\n",
      "Epoch 10/10\n",
      " 4035/12310 [========>.....................] - ETA: 31s - loss: 0.8319"
     ]
    }
   ],
   "source": [
    "linear_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error')\n",
    "\n",
    "history = linear_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    # Suppress logging.\n",
    "    verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6834efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "test_results['linear_model'] = linear_model.evaluate(\n",
    "    test_features, test_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb1f19d",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "mlp_model = keras.Sequential([\n",
    "  normalizer,\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "mlp_model.compile(loss='mean_absolute_error',\n",
    "            optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = mlp_model.fit(\n",
    "    train_features, #.values.astype(np.float32)\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=10)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['mlp_model'] = mlp_model.evaluate(test_features, test_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_results, index=['Mean absolute error [MPG]']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf4b461",
   "metadata": {},
   "source": [
    "Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_linear = linear_model.predict(test_features).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_labels, test_predictions_linear)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "lims = [0, 50]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeba011",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_mlp = mlp_model.predict(test_features).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_labels, test_predictions_mlp)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "lims = [0, 50]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution des erreurs\n",
    "\n",
    "error_linear = test_predictions_linear - test_labels\n",
    "plt.hist(error_linear, bins=25)\n",
    "plt.xlabel('Prediction Error [MPG]')\n",
    "_ = plt.ylabel('Count')\n",
    "\n",
    "error_mlp = test_predictions_mlp - test_labels\n",
    "plt.hist(error_mlp, bins=25)\n",
    "plt.xlabel('Prediction Error [MPG]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "linear_model.save('linear_model')\n",
    "mlp_model.save('mlp_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utiliser\n",
    "\n",
    "url_test_with_reading_time_NaN = 'src/data/initial/goodreads_test_with_reading_time_NaN.csv'\n",
    "url_test_with_reading_time = 'src/data/initial/goodreads_test_with_reading_time.csv'\n",
    "url_test_not_reading_time = 'src/data/initial/goodreads_test_not_reading_time.csv'\n",
    "\n",
    "raw_dataset_test = pd.read_csv(url_test_with_reading_time_NaN, \n",
    "                          na_values='?', sep=',')\n",
    "\n",
    "raw_dataset_test = raw_dataset_test.drop(['review_id'], axis=1) \n",
    "dataset_test = raw_dataset_test.copy()\n",
    "\n",
    "dataset_test = dataset_test.dropna()\n",
    "\n",
    "train_dataset_test = dataset_test.sample(frac=0.8, random_state=0)\n",
    "test_dataset_test = dataset_test.drop(train_dataset_test.index)\n",
    "\n",
    "test_features_test = test_dataset_test.copy()\n",
    "\n",
    "test_labels_test = test_features_test.pop('rating')\n",
    "\n",
    "reloaded = tf.keras.models.load_model('mlp_model')\n",
    "\n",
    "test_results['reloaded'] = reloaded.evaluate(\n",
    "    test_features_test, test_labels_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a6555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e4d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053cb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b014eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53fa5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
