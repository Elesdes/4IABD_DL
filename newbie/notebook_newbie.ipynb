{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Load Libs**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import math\n",
    "# Native python libs\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Any"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# pip installed libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Paths**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "BASE_PATH = f\"{os.path.abspath('')}\\\\..\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Kaggle**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "KAGGLE = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "KAGGLE_PATH = \"/kaggle\" if KAGGLE else f\"{BASE_PATH}\\\\kaggle\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def submission_path_exists() -> str:\n",
    "    directory = f\"{KAGGLE_PATH}\\\\working\\\\{datetime.now().strftime('%d%m%Y')}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "        print(f\"Created new output directory for today at '{directory}'\")\n",
    "    return directory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "INPUT_PATH = f\"{KAGGLE_PATH}\\\\input\\\\goodreads-books-reviews-290312\"\n",
    "OUTPUT_PATH = submission_path_exists()\n",
    "SUBMISSION_PATH = f\"{OUTPUT_PATH}\\\\{datetime.now().strftime('%H%M%S')}_submission.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Tensorboard & General Monitoring**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "TENSORBOARD_LOGS_PATH = f\"{BASE_PATH}\\\\tensorboard_logs\"\n",
    "KERAS_TUNER_MONITOR_PATH = f\"{OUTPUT_PATH}\\\\keras_tuner_monitoring\"\n",
    "MONITOR_PATH = f\"{OUTPUT_PATH}\\\\monitoring.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# Machine Learning tensorboard paths\n",
    "TENSORBOARD_LOGS_PATH_ML = f\"{TENSORBOARD_LOGS_PATH}\\\\ML\"\n",
    "LINEAR = f\"{TENSORBOARD_LOGS_PATH_ML}\\\\Linear\"\n",
    "MLP = f\"{TENSORBOARD_LOGS_PATH_ML}\\\\MLP\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Deep Learning tensorboard paths\n",
    "TENSORBOARD_LOGS_PATH_DL = f\"{TENSORBOARD_LOGS_PATH}\\\\DL\"\n",
    "CNN = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\CNN\"\n",
    "RESNET = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\ResNet\"\n",
    "RNN = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\RNN\"\n",
    "SIMPLE_RNN = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\SimpleRNN\"\n",
    "TRANSFORMER = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\Transformer\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\juanm\\\\OneDrive\\\\Bureau\\\\ESGI - Projets\\\\4IABD\\\\Projet Deep Learning\\\\tensorboard_logs'"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if path is good\n",
    "os.path.abspath(TENSORBOARD_LOGS_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hyperparameters**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Fix\n",
    "CLASSES = 6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# Adjustable\n",
    "BATCH_SIZE = 1024  # Big batch size, small learning rate\n",
    "VOCAB_SIZE = 20000\n",
    "SEQUENCE_LENGTH = 256\n",
    "EMBEDDING_DIMS = 128\n",
    "EPOCHS = 100\n",
    "TRIALS = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load Datasets**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(f\"{INPUT_PATH}\\\\goodreads_train.csv\",\n",
    "                            usecols=['review_text', 'rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(f\"{INPUT_PATH}\\\\goodreads_test.csv\",\n",
    "                           usecols=['review_text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**GPU/TPU MultiThreading Setup**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "    strategy = tf.distribute.experimental.TPUStrategy\n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print('Number of replicas:', strategy.num_replicas_in_sync)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "    gpus = tf.config.experimental.list_logical_devices(\"GPU\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on single GPU  /device:GPU:0\n",
      "Number of accelerators:  1\n"
     ]
    }
   ],
   "source": [
    "if tpu:\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu, )\n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "elif len(gpus) > 1:\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy([gpu.name for gpu in gpus])\n",
    "    print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
    "elif len(gpus) == 1:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print('Running on single GPU ', gpus[0].name)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print('Running on CPU')\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NLP**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Create a TextVectorization layer\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(standardize=None,\n",
    "                                                    output_sequence_length=SEQUENCE_LENGTH,\n",
    "                                                    output_mode='int')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13.4 s\n",
      "Wall time: 47.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    vectorize_layer.adapt(train_dataset['review_text'], batch_size=BATCH_SIZE * strategy.num_replicas_in_sync)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n '[UNK]',\n 'the',\n 'and',\n 'I',\n 'to',\n 'a',\n 'of',\n 'is',\n 'was',\n 'in',\n 'that',\n 'it',\n 'this',\n 'for',\n 'but',\n 'with',\n 'book',\n 'her',\n 'as',\n 'The',\n 'so',\n 'not',\n 'she',\n 'have',\n 'be',\n 'on',\n 'you',\n 'like',\n 'just',\n 'my',\n 'about',\n 'are',\n 'really',\n 'he',\n 'me',\n 'at',\n 'his',\n 'read',\n 'all',\n 'one',\n 'more',\n 'from',\n 'they',\n 'what',\n 'an',\n 'story',\n 'love',\n 'has',\n 'had',\n 'how',\n 'It',\n 'This',\n 'who',\n 'because',\n 'out',\n 'up',\n 'or',\n 'by',\n 'when',\n 'were',\n \"I'm\",\n 'would',\n 'their',\n 'much',\n 'some',\n 'get',\n \"didn't\",\n 'very',\n 'if',\n '-',\n 'there',\n 'characters',\n 'will',\n 'into',\n 'can',\n \"it's\",\n 'even',\n 'think',\n 'first',\n 'And',\n \"don't\",\n 'than',\n 'But',\n 'know',\n 'book.',\n 'also',\n 'been',\n 'it.',\n 'other',\n 'loved',\n 'only',\n 'good',\n 'reading',\n 'time',\n 'see',\n 'did',\n 'way',\n 'we',\n 'him',\n 'could',\n 'them',\n 'no',\n 'which',\n 'little',\n 'do',\n 'still',\n 'going',\n 'being',\n 'books',\n 'She',\n 'things',\n 'too',\n 'felt',\n \"It's\",\n 'made',\n 'feel',\n 'want',\n 'liked',\n 'series',\n 'never',\n 'book,',\n 'lot',\n 'character',\n 'people',\n 'make',\n 'after',\n 'where',\n 'two',\n 'then',\n 'bit',\n \"wasn't\",\n \"can't\",\n 'most',\n 'There',\n 'something',\n 'many',\n 'He',\n 'through',\n 'got',\n 'great',\n 'between',\n 'A',\n 'world',\n 'say',\n 'me.',\n 'am',\n 'thought',\n 'end',\n 'over',\n 'find',\n \"I've\",\n 'any',\n \"doesn't\",\n 'these',\n 'enjoyed',\n 'life',\n 'your',\n 'back',\n 'well',\n 'each',\n 'found',\n 'plot',\n 'while',\n 'go',\n 'new',\n 'those',\n 'writing',\n 'though',\n 'always',\n 'next',\n 'In',\n 'thing',\n 'kind',\n 'why',\n 'story.',\n 'actually',\n 'pretty',\n 'So',\n 'few',\n 'off',\n 'definitely',\n 'does',\n 'both',\n 'such',\n 'best',\n 'wanted',\n 'every',\n 'it,',\n 'makes',\n 'part',\n 'quite',\n 'If',\n 'whole',\n 'different',\n 'main',\n 'novel',\n 'everything',\n 'own',\n 'author',\n 'interesting',\n 'give',\n 'last',\n 'right',\n 'sure',\n 'better',\n 'before',\n 'same',\n 'its',\n \"she's\",\n \"that's\",\n 'enough',\n 'ever',\n 'take',\n 'romance',\n 'They',\n 'now',\n 'come',\n 'should',\n \"isn't\",\n 'What',\n 'hard',\n 'since',\n 'put',\n \"couldn't\",\n 'around',\n 'ending',\n 'review',\n 'relationship',\n 'down',\n 'another',\n 'read.',\n 'i',\n 'her.',\n 'without',\n 'long',\n 'You',\n 'series.',\n 'As',\n 'bad',\n 'need',\n \"he's\",\n 'until',\n 'real',\n '(hide',\n 'might',\n 'stars',\n 'keep',\n 'left',\n '(view',\n 'second',\n 'favorite',\n 'me,',\n 'anything',\n 'girl',\n 'them.',\n 'When',\n 'start',\n 'My',\n 'That',\n \"I'd\",\n 'point',\n 'started',\n 'family',\n 'trying',\n 'him.',\n 'may',\n 'wait',\n 'almost',\n 'probably',\n 'away',\n 'someone',\n 'story,',\n 'Not',\n 'getting',\n 'our',\n 'myself',\n 'years',\n 'times',\n \"I'll\",\n 'spoiler)]',\n 'nothing',\n 'fact',\n 'enjoy',\n 'help',\n 'especially',\n 'seems',\n 'completely',\n 'took',\n 'seemed',\n 'having',\n 'written',\n 'understand',\n 'characters.',\n 'looking',\n 'gets',\n 'fun',\n 'work',\n \"there's\",\n 'us',\n 'comes',\n 'together',\n 'one.',\n 'kept',\n 'heart',\n 'We',\n 'big',\n 'recommend',\n 'let',\n 'For',\n 'knew',\n 'characters,',\n 'everyone',\n 'able',\n \"you're\",\n 'person',\n 'man',\n 'finally',\n 'came',\n 'once',\n 'stories',\n 'tell',\n 'happy',\n 'that.',\n 'look',\n 'yet',\n 'old',\n 'went',\n 'full',\n 'All',\n 'young',\n 'least',\n 'past',\n 'perfect',\n 'happened',\n 'far',\n 'rather',\n 'time.',\n 'maybe',\n 'series,',\n 'idea',\n 'takes',\n 'set',\n 'One',\n 'pages',\n 'absolutely',\n 'believe',\n 'seem',\n 'three',\n 'hope',\n 'However,',\n 'place',\n 'friends',\n 'strong',\n 'herself',\n 'here',\n 'said',\n 'care',\n 'amazing',\n 'done',\n 'While',\n 'Her',\n 'already',\n 'wants',\n 'told',\n 'less',\n 'feeling',\n '&',\n 'beginning',\n 'high',\n 'must',\n 'that,',\n '5',\n 'wish',\n 'At',\n 'half',\n 'sense',\n 'totally',\n 'glad',\n 'beautiful',\n 'Even',\n '--',\n '.',\n 'life.',\n 'again',\n 'reason',\n 'her,',\n 'goes',\n 'easy',\n 'feels',\n 'end.',\n 'become',\n 'mind',\n 'nice',\n 'books.',\n 'YA',\n 'forward',\n 'well.',\n 'making',\n \"won't\",\n 'hate',\n 'couple',\n 'all.',\n 'reader',\n 'After',\n 'guy',\n 'truly',\n 'mean',\n 'parts',\n 'anyone',\n 'entire',\n \"She's\",\n 'more.',\n 'rest',\n 'day',\n 'gave',\n 'knows',\n 'school',\n 'live',\n 'year',\n 'friend',\n \"wouldn't\",\n 'way.',\n 'used',\n 'short',\n 'action',\n 'sort',\n 'feelings',\n 'sex',\n 'try',\n 'coming',\n 'read,',\n 'scenes',\n 'this.',\n 'along',\n 'out.',\n 'happens',\n \"There's\",\n 'side',\n 'fantasy',\n '(and',\n 'job',\n 'write',\n 'throughout',\n 'stop',\n 'woman',\n 'guess',\n \"He's\",\n \"they're\",\n 'seeing',\n 'fan',\n 'given',\n 'thinking',\n '4',\n 'mystery',\n 'lost',\n 'exactly',\n 'happen',\n 'else',\n 'all,',\n 'true',\n 'boy',\n 'finished',\n 'stars.',\n 'sometimes',\n '3',\n 'up.',\n 'him,',\n 'character.',\n 'novel.',\n 'To',\n 'time,',\n 'fall',\n 'Just',\n 'mother',\n '**',\n 'doing',\n 'worth',\n 'remember',\n 'sweet',\n 'books,',\n 'although',\n 'instead',\n 'lives',\n 'learn',\n 'readers',\n 'father',\n 'ended',\n 'change',\n 'dark',\n 'again.',\n 'needed',\n 'course',\n 'Then',\n 'human',\n 'during',\n 'Also,',\n 'honest',\n 'saw',\n 'head',\n 'end,',\n 'much.',\n 'this,',\n 'Maybe',\n 'good.',\n 'too.',\n 'is,',\n 'seen',\n 'though,',\n 'often',\n 'against',\n 'His',\n 'page',\n 'pick',\n 'issues',\n 'moments',\n 'one,',\n 'others',\n 'starts',\n 'How',\n 'emotional',\n 'them,',\n 'wonderful',\n 'style',\n 'words',\n 'on.',\n 'giving',\n 'use',\n 'previous',\n 'despite',\n 'slow',\n 'world.',\n 'Now',\n 'scene',\n 'character,',\n 'magic',\n 'needs',\n 'problem',\n 'finds',\n 'important',\n \"haven't\",\n \"That's\",\n '\"I',\n 'finish',\n 'huge',\n 'leave',\n 'himself',\n 'spoiler)[',\n 'cannot',\n '2',\n 'turn',\n 'show',\n 'supposed',\n 'turned',\n 'No',\n 'third',\n 'female',\n 'funny',\n 'reviews',\n 'sad',\n 'is.',\n 'talk',\n 'THE',\n 'certain',\n 'women',\n 'Like',\n 'fell',\n '3.5',\n 'wrong',\n 'small',\n 'well,',\n 'you.',\n 'hot',\n 'With',\n 'Overall,',\n 'expect',\n 'towards',\n 'Some',\n 'movie',\n 'became',\n 'novel,',\n 'moment',\n 'simply',\n 'life,',\n 'behind',\n 'together.',\n 'Book',\n 'star',\n 'On',\n '(I',\n 'home',\n 'several',\n 'interested',\n 'living',\n 'Because',\n 'surprised',\n 'down.',\n 'matter',\n 'love.',\n 'excited',\n 'decided',\n 'deal',\n 'turns',\n 'expected',\n 'future',\n 'super',\n 'eyes',\n 'unique',\n 'death',\n 'mostly',\n 'parents',\n 'events',\n ':)',\n 'said,',\n 'figure',\n 'middle',\n \"aren't\",\n 'So,',\n 'heroine',\n 'usually',\n 'picked',\n 'certainly',\n 'it!',\n 'girls',\n 'name',\n 'saying',\n 'there.',\n 'close',\n 'other.',\n 'either',\n 'later',\n 'meet',\n 'did.',\n 'though.',\n 'difficult',\n 'final',\n 'book!',\n 'chapters',\n 'highly',\n 'soon',\n 'again,',\n 'face',\n 'becomes',\n 'under',\n 'here.',\n 'ends',\n 'you,',\n 'honestly',\n 'extremely',\n 'mean,',\n 'way,',\n 'continue',\n 'romantic',\n 'crazy',\n 'single',\n 'ending.',\n 'Why',\n 'copy',\n 'review.',\n 'chapter',\n 'now.',\n 'fast',\n 'gives',\n 'experience',\n 'novels',\n 'awesome',\n 'heard',\n 'taking',\n 'taken',\n 'overall',\n 'be.',\n 'stand',\n 'stuff',\n '4.5',\n 'kill',\n 'within',\n 'love,',\n 'stay',\n 'men',\n 'called',\n 'means',\n 'wanting',\n 'interest',\n 'better.',\n 'expecting',\n 'line',\n 'meets',\n 'cover',\n 'particularly',\n 'brother',\n 'in.',\n 'original',\n 'course,',\n 'waiting',\n 'sister',\n 'quickly',\n 'across',\n 'incredibly',\n 'quick',\n 'save',\n 'type',\n 'light',\n 'Of',\n 'spoiler',\n 'history',\n 'realize',\n 'Although',\n 'move',\n 'good,',\n 'development',\n 'Oh',\n 'world,',\n 'four',\n 'admit',\n 'brought',\n 'basically',\n 'Well,',\n 'adult',\n 'case',\n 'up,',\n 'loves',\n 'chance',\n 'setting',\n 'twists',\n 'play',\n 'out,',\n 'whether',\n 'hoping',\n 'power',\n 'fight',\n 'five',\n 'disappointed',\n 'enjoyable',\n 'easily',\n 'Will',\n 'night',\n 'cute',\n 'talking',\n 'fantastic',\n 'order',\n 'works',\n 'tale',\n 'tried',\n 'Yes,',\n 'clear',\n 'Review',\n 'twist',\n 'First',\n 'thoughts',\n 'New',\n \"what's\",\n 'major',\n 'lack',\n 'weird',\n 'Harry',\n 'hero',\n 'itself',\n 'hated',\n 'ones',\n 'shows',\n 'fiction',\n 'personal',\n 'building',\n '...',\n 'kids',\n 'word',\n 'finding',\n 'historical',\n 'actual',\n 'favourite',\n 'days',\n 'telling',\n 'keeps',\n 'hell',\n 'romance.',\n 'Read',\n 'follow',\n 'emotions',\n 'knowing',\n 'journey',\n 'on,',\n 'ways',\n \"you'll\",\n 'was.',\n 'times.',\n 'top',\n 'romance,',\n 'based',\n 'group',\n 'male',\n 'questions',\n 'lots',\n 'bring',\n \"weren't\",\n 'These',\n 'Their',\n 'problems',\n 'to.',\n 'call',\n 'reading.',\n 'interesting.',\n 'sexy',\n 'complete',\n 'about.',\n 'exchange',\n 'break',\n 'know,',\n 'worked',\n 'times,',\n 'authors',\n 'spent',\n 'voice',\n 'points',\n 'known',\n 'mention',\n 'tells',\n 'Or',\n 'literally',\n 'town',\n 'From',\n 'friendship',\n 'age',\n 'similar',\n 'says',\n 'trust',\n 'forced',\n 'due',\n 'evil',\n 'watching',\n 'deep',\n 'except',\n 'focus',\n 'annoying',\n 'relationships',\n 'hold',\n 'early',\n 'somewhat',\n 'sexual',\n 'details',\n 'themselves',\n 'run',\n 'guys',\n 'Another',\n 'children',\n 'SO',\n 'met',\n 'inside',\n 'rating',\n 'magical',\n 'wonder',\n 'meant',\n 'however,',\n 'working',\n 'connection',\n 'amount',\n 'seriously',\n 'now,',\n 'free',\n 'But,',\n 'longer',\n 'plot.',\n 'view',\n \"Don't\",\n 'realistic',\n 'war',\n 'secret',\n 'thinks',\n 'changed',\n 'killed',\n 'drama',\n 'situation',\n 'beyond',\n 'elements',\n 'open',\n 'fully',\n 'say,',\n 'thing.',\n 'reminded',\n 'fact,',\n 'obvious',\n 'grow',\n 'attention',\n 'Love',\n 'AND',\n '\"The',\n 'appreciate',\n 'starting',\n 'tries',\n 'slightly',\n 'away.',\n 'alert',\n 'immediately',\n 'grew',\n 'imagine',\n 'lead',\n '(which',\n \"you've\",\n 'people.',\n 'received',\n 'hands',\n 'hit',\n 'typical',\n 'added',\n 'loving',\n 'first,',\n 'missing',\n 'strange',\n 'premise',\n 'boring',\n 'plot,',\n 'dead',\n 'fit',\n 'serious',\n 'really,',\n 'developed',\n 'Is',\n 'there,',\n 'somehow',\n 'filled',\n '(or',\n 'created',\n 'issue',\n 'Stars',\n 'not.',\n 'entirely',\n 'with.',\n 'version',\n 'child',\n 'mentioned',\n 'powerful',\n 'cool',\n 'Ms.',\n 'present',\n 'Which',\n 'constantly',\n 'hurt',\n 'complex',\n 'upon',\n 'special',\n 'was,',\n 'Though',\n 'ready',\n 'slowly',\n 'information',\n 'sequel',\n 'King',\n 'entertaining',\n 'annoyed',\n 'nearly',\n 'interesting,',\n 'concept',\n 'together,',\n 'happening',\n 'house',\n 'clearly',\n 'aspect',\n 'storyline',\n 'do.',\n 'normal',\n 'realized',\n 'wrote',\n 'alone',\n 'add',\n 'leaves',\n 'falling',\n 'Loved',\n 'whose',\n 'begins',\n 'perhaps',\n 'kinda',\n 'hear',\n 'Once',\n '*',\n '(the',\n 'mysterious',\n 'stupid',\n 'older',\n 'Kate',\n 'heart.',\n 'society',\n 'excellent',\n 'drawn',\n 'great.',\n 'question',\n 'okay',\n 'gone',\n 'An',\n 'writes',\n 'here,',\n 'fairly',\n 'Also',\n 'willing',\n 'amazing.',\n 'Overall',\n 'narrative',\n 'near',\n 'Every',\n 'begin',\n 'things.',\n 'family.',\n ...]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def vectorize_text(text: Any, label: Any) -> Any:\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Creating Dataset For Models**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def dataset_from_raw_data(x: np.ndarray, y: np.ndarray, batch_size: int = BATCH_SIZE) -> Any:\n",
    "    # Create dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)\n",
    "    # Vectorize\n",
    "    dataset = dataset.map(vectorize_text)\n",
    "    print(dataset.element_spec)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Linear**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def linear() -> tf.keras.Sequential:\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(CLASSES, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**MLP**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def mlp() -> tf.keras.Sequential:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "    model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=384, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(CLASSES, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**CNN**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def cnn() -> tf.keras.Sequential:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int32))\n",
    "    model.add(tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS))\n",
    "    model.add(tf.keras.layers.Reshape((math.isqrt(SEQUENCE_LENGTH), math.isqrt(SEQUENCE_LENGTH), -1),\n",
    "                                      input_shape=(None, SEQUENCE_LENGTH)))\n",
    "\n",
    "    # Conv & pooling tf.keras.layers\n",
    "    model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "    # Fully connected tf.keras.layers\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(CLASSES, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**RNN**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "def rnn() -> tf.keras.Sequential:\n",
    "    inputs = tf.keras.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    x = tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS)(inputs)\n",
    "    for i in range(2):\n",
    "        x = tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(32, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(16, return_sequences=False))(x)\n",
    "    x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(CLASSES, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Utilitary For Monitoring**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def tensorboard_logs(model_name: str) -> tf.keras.callbacks.TensorBoard:\n",
    "    return tf.keras.callbacks.TensorBoard(f\"{globals()[model_name.upper()]}\"\n",
    "                                          f\"_BS_{BATCH_SIZE}\"\n",
    "                                          f\"_MAXFEAT_{VOCAB_SIZE}\"\n",
    "                                          f\"_EMBEDDING_{EMBEDDING_DIMS}\"\n",
    "                                          f\"_SEQLEN_{SEQUENCE_LENGTH}\"\n",
    "                                          f\"_EPOCHS_{EPOCHS}\"\n",
    "                                          f\"_TRIALS_{TRIALS}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def epochs_logs(model_name: str) -> tf.keras.callbacks.CSVLogger:\n",
    "    return tf.keras.callbacks.CSVLogger(f\"{globals()[model_name.upper()]}\"\n",
    "                                        f\"_BS_{BATCH_SIZE}\"\n",
    "                                        f\"_MAXFEAT_{VOCAB_SIZE}\"\n",
    "                                        f\"_EMBEDDING_{EMBEDDING_DIMS}\"\n",
    "                                        f\"_SEQLEN_{SEQUENCE_LENGTH}\"\n",
    "                                        f\"_EPOCHS_{EPOCHS}\"\n",
    "                                        f\"_TRIALS_{TRIALS}.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n",
      "(TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n",
      "Epoch 1/10\n",
      "704/704 [==============================] - 46s 64ms/step - loss: 1.6195 - accuracy: 0.3451 - val_loss: 1.4999 - val_accuracy: 0.3472\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 44s 63ms/step - loss: 1.4795 - accuracy: 0.3490 - val_loss: 1.4670 - val_accuracy: 0.3474\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 44s 62ms/step - loss: 1.4563 - accuracy: 0.3508 - val_loss: 1.4461 - val_accuracy: 0.3531\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 43s 61ms/step - loss: 1.4318 - accuracy: 0.3702 - val_loss: 1.4184 - val_accuracy: 0.3827\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 44s 62ms/step - loss: 1.4010 - accuracy: 0.4046 - val_loss: 1.3859 - val_accuracy: 0.4146\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 43s 61ms/step - loss: 1.3679 - accuracy: 0.4313 - val_loss: 1.3537 - val_accuracy: 0.4358\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 43s 60ms/step - loss: 1.3370 - accuracy: 0.4477 - val_loss: 1.3252 - val_accuracy: 0.4492\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 41s 59ms/step - loss: 1.3101 - accuracy: 0.4579 - val_loss: 1.3009 - val_accuracy: 0.4576\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 42s 60ms/step - loss: 1.2872 - accuracy: 0.4654 - val_loss: 1.2802 - val_accuracy: 0.4648\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 43s 61ms/step - loss: 1.2675 - accuracy: 0.4725 - val_loss: 1.2624 - val_accuracy: 0.4714\n",
      "176/176 [==============================] - 8s 44ms/step - loss: 1.2624 - accuracy: 0.4714\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\juanm\\OneDrive\\Bureau\\ESGI - Projets\\4IABD\\Projet Deep Learning\\newbie\\..\\kaggle\\working\\24022023\\linear_loss_1.2623987197875977_acc_0.4714333415031433\\assets\n",
      "(TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n",
      "(TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n",
      "Epoch 1/10\n",
      " 6/47 [==>...........................] - ETA: 34s - loss: 1.7879 - accuracy: 0.2608"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [77]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m y \u001B[38;5;241m=\u001B[39m dataset_from_raw_data(y[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreview_text\u001B[39m\u001B[38;5;124m'\u001B[39m], y[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrating\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m      8\u001B[0m                           batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n\u001B[0;32m      9\u001B[0m model_to_train \u001B[38;5;241m=\u001B[39m model()\n\u001B[1;32m---> 10\u001B[0m \u001B[43mmodel_to_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mstop_early\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensorboard_logs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs_logs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m eval_result \u001B[38;5;241m=\u001B[39m model_to_train\u001B[38;5;241m.\u001B[39mevaluate(y)\n\u001B[0;32m     13\u001B[0m model_to_train\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mOUTPUT_PATH\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     14\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     15\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_loss_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00meval_result[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     16\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_acc_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00meval_result[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# In case of multiple models training\n",
    "with strategy.scope():\n",
    "    for model in [linear, mlp, cnn, rnn]:\n",
    "        for batch_size in [1024, 15600, 56333, 18000, 23256]:\n",
    "            x, y = model_selection.train_test_split(train_dataset, test_size=0.2)\n",
    "            x = dataset_from_raw_data(x['review_text'], x['rating'], batch_size=batch_size)\n",
    "            y = dataset_from_raw_data(y['review_text'], y['rating'],\n",
    "                                      batch_size=batch_size)\n",
    "            model_to_train = model()\n",
    "            model_to_train.fit(x, validation_data=y, epochs=10,\n",
    "                               callbacks=[stop_early, tensorboard_logs(model.__name__), epochs_logs(model.__name__)])\n",
    "            eval_result = model_to_train.evaluate(y)\n",
    "            model_to_train.save(f\"{OUTPUT_PATH}\\\\\"\n",
    "                                f\"{model.__name__}\"\n",
    "                                f\"_loss_{eval_result[0]}\"\n",
    "                                f\"_acc_{eval_result[1]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Evaluation**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = [dir for root, dirs, files in os.walk(f'{KAGGLE_PATH}/working') for dir in dirs if dir.__contains__(\"acc\")]\n",
    "sort_models_per_acc = sorted(models, key=lambda x: float(x[x.find('_acc_') + 5:]), reverse=True)\n",
    "sort_models_per_loss = sorted(models, key=lambda x: float(x[x.find('_loss_') + 6:x.find('_acc_')]))\n",
    "print(sort_models_per_acc)\n",
    "print(sort_models_per_loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(f\"{KAGGLE_PATH}/working/{sort_models_per_acc[0]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Submission**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['review_id'] = [data.decode(\"utf-8\") for data in test_dataset['review_id']]\n",
    "submission['rating'] = best_model.predict(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "print(f\"Submission registered at {SUBMISSION_PATH}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
