{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Import libraries**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Default parameters**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "MAX_SIZE = 399\n",
    "NUM_WORDS = 1000\n",
    "EMBEDDING_DIM = 16\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 255\n",
    "OOV = 1\n",
    "SARCASM_TRAINING_SIZE = 20000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Creating DataFrames**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "goodreads_train = pd.read_csv(\"C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/initial/goodreads_train.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 user_id   book_id  \\\n358954  b104c4c0c9e1fbef82b4f94fa156524e    345627   \n305386  414854ccbe367d9cb5a97d159b40cf2f     19501   \n179053  c96ef78de7028e9ed7002356fb800a52     17245   \n214749  a143ad96df0ebd75024fc42c5a4c41f1  30194656   \n430736  6057d7eac9ffd0006c289e86a1f70236  28599180   \n\n                               review_id  rating  \\\n358954  3d9bef781340b06e4439a73d7c371def       3   \n305386  7f11cc0f099f5488ce24d812a1c94076       0   \n179053  415cfa19e48d2cbb6f08e7096487ec88       2   \n214749  f0e740f43f1e82ea269ab39d935c3868       5   \n430736  d63e62b3223b403afe1ce52d2d3105cf       5   \n\n                                              review_text  \\\n358954  3.5 stars \\n Super fun adolescent vampire dram...   \n305386  After reading the reviews for this book, it ju...   \n179053  -Original Review- \\n I bet those who read this...   \n214749  5 \" Beyond Labels\" Stars \\n It's official. Aly...   \n430736  Absolutely awesome conclusion to this series. ...   \n\n                            date_added                    date_updated  \\\n358954  Sat May 26 13:34:24 -0700 2012  Fri Mar 11 18:27:48 -0800 2016   \n305386  Thu Mar 25 19:48:34 -0700 2010  Thu Mar 25 19:48:58 -0700 2010   \n179053  Sun Sep 15 13:08:59 -0700 2013  Mon Jan 09 22:42:12 -0800 2017   \n214749  Wed Oct 14 17:56:07 -0700 2015  Fri May 27 02:23:36 -0700 2016   \n430736  Mon Feb 15 21:35:48 -0800 2016  Wed Apr 20 18:29:43 -0700 2016   \n\n                               read_at                      started_at  \\\n358954  Thu Mar 10 00:00:00 -0800 2016  Mon Mar 07 00:00:00 -0800 2016   \n305386                             NaN                             NaN   \n179053                             NaN                             NaN   \n214749  Thu May 19 00:00:00 -0700 2016  Thu May 19 00:00:00 -0700 2016   \n430736  Tue Apr 19 00:00:00 -0700 2016  Mon Apr 18 00:00:00 -0700 2016   \n\n        n_votes  n_comments  \n358954       36           6  \n305386        0           0  \n179053        0           0  \n214749       22          16  \n430736        0           0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>rating</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>358954</th>\n      <td>b104c4c0c9e1fbef82b4f94fa156524e</td>\n      <td>345627</td>\n      <td>3d9bef781340b06e4439a73d7c371def</td>\n      <td>3</td>\n      <td>3.5 stars \\n Super fun adolescent vampire dram...</td>\n      <td>Sat May 26 13:34:24 -0700 2012</td>\n      <td>Fri Mar 11 18:27:48 -0800 2016</td>\n      <td>Thu Mar 10 00:00:00 -0800 2016</td>\n      <td>Mon Mar 07 00:00:00 -0800 2016</td>\n      <td>36</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>305386</th>\n      <td>414854ccbe367d9cb5a97d159b40cf2f</td>\n      <td>19501</td>\n      <td>7f11cc0f099f5488ce24d812a1c94076</td>\n      <td>0</td>\n      <td>After reading the reviews for this book, it ju...</td>\n      <td>Thu Mar 25 19:48:34 -0700 2010</td>\n      <td>Thu Mar 25 19:48:58 -0700 2010</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>179053</th>\n      <td>c96ef78de7028e9ed7002356fb800a52</td>\n      <td>17245</td>\n      <td>415cfa19e48d2cbb6f08e7096487ec88</td>\n      <td>2</td>\n      <td>-Original Review- \\n I bet those who read this...</td>\n      <td>Sun Sep 15 13:08:59 -0700 2013</td>\n      <td>Mon Jan 09 22:42:12 -0800 2017</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>214749</th>\n      <td>a143ad96df0ebd75024fc42c5a4c41f1</td>\n      <td>30194656</td>\n      <td>f0e740f43f1e82ea269ab39d935c3868</td>\n      <td>5</td>\n      <td>5 \" Beyond Labels\" Stars \\n It's official. Aly...</td>\n      <td>Wed Oct 14 17:56:07 -0700 2015</td>\n      <td>Fri May 27 02:23:36 -0700 2016</td>\n      <td>Thu May 19 00:00:00 -0700 2016</td>\n      <td>Thu May 19 00:00:00 -0700 2016</td>\n      <td>22</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>430736</th>\n      <td>6057d7eac9ffd0006c289e86a1f70236</td>\n      <td>28599180</td>\n      <td>d63e62b3223b403afe1ce52d2d3105cf</td>\n      <td>5</td>\n      <td>Absolutely awesome conclusion to this series. ...</td>\n      <td>Mon Feb 15 21:35:48 -0800 2016</td>\n      <td>Wed Apr 20 18:29:43 -0700 2016</td>\n      <td>Tue Apr 19 00:00:00 -0700 2016</td>\n      <td>Mon Apr 18 00:00:00 -0700 2016</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodreads_train.sample(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Cleaning Data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                          review_id  rating  \\\n0  dfdbb7b0eb5a7e4c26d59a937e2e5feb       5   \n1  a5d2c3628987712d0e05c4f90798eb67       3   \n2  2ede853b14dc4583f96cf5d120af636f       3   \n3  ced5675e55cd9d38a524743f5c40996e       0   \n4  332732725863131279a8e345b63ac33e       4   \n\n                                         review_text  n_votes  n_comments  \n0  This is a special book. It started slow for ab...       28           1  \n1  Recommended by Don Katz. Avail for free in Dec...        1           0  \n2  A fun, fast paced science fiction thriller. I ...       22           0  \n3  Recommended reading to understand what is goin...        5           1  \n4  I really enjoyed this book, and there is a lot...        9           1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>rating</th>\n      <th>review_text</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dfdbb7b0eb5a7e4c26d59a937e2e5feb</td>\n      <td>5</td>\n      <td>This is a special book. It started slow for ab...</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a5d2c3628987712d0e05c4f90798eb67</td>\n      <td>3</td>\n      <td>Recommended by Don Katz. Avail for free in Dec...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2ede853b14dc4583f96cf5d120af636f</td>\n      <td>3</td>\n      <td>A fun, fast paced science fiction thriller. I ...</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ced5675e55cd9d38a524743f5c40996e</td>\n      <td>0</td>\n      <td>Recommended reading to understand what is goin...</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>332732725863131279a8e345b63ac33e</td>\n      <td>4</td>\n      <td>I really enjoyed this book, and there is a lot...</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = goodreads_train.drop(columns=['user_id', 'book_id', 'date_added', 'date_updated', 'read_at', 'started_at'],\n",
    "                                axis=0)\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "review_id      object\nrating          int64\nreview_text    object\nn_votes         int64\nn_comments      int64\ndtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y_train = train_df['rating']\n",
    "x_train = train_df.drop('rating', axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                          review_id  \\\n0  dfdbb7b0eb5a7e4c26d59a937e2e5feb   \n1  a5d2c3628987712d0e05c4f90798eb67   \n2  2ede853b14dc4583f96cf5d120af636f   \n3  ced5675e55cd9d38a524743f5c40996e   \n4  332732725863131279a8e345b63ac33e   \n\n                                         review_text  n_votes  n_comments  \n0  This is a special book. It started slow for ab...       28           1  \n1  Recommended by Don Katz. Avail for free in Dec...        1           0  \n2  A fun, fast paced science fiction thriller. I ...       22           0  \n3  Recommended reading to understand what is goin...        5           1  \n4  I really enjoyed this book, and there is a lot...        9           1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>review_text</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dfdbb7b0eb5a7e4c26d59a937e2e5feb</td>\n      <td>This is a special book. It started slow for ab...</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a5d2c3628987712d0e05c4f90798eb67</td>\n      <td>Recommended by Don Katz. Avail for free in Dec...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2ede853b14dc4583f96cf5d120af636f</td>\n      <td>A fun, fast paced science fiction thriller. I ...</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ced5675e55cd9d38a524743f5c40996e</td>\n      <td>Recommended reading to understand what is goin...</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>332732725863131279a8e345b63ac33e</td>\n      <td>I really enjoyed this book, and there is a lot...</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0    5\n1    3\n2    3\n3    0\n4    4\nName: rating, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "x_train['review_id'] = le.fit_transform(x_train['review_id'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   review_id                                        review_text  n_votes  \\\n0     786842  This is a special book. It started slow for ab...       28   \n1     583423  Recommended by Don Katz. Avail for free in Dec...        1   \n2     165147  A fun, fast paced science fiction thriller. I ...       22   \n3     727692  Recommended reading to understand what is goin...        5   \n4     179941  I really enjoyed this book, and there is a lot...        9   \n\n   n_comments  \n0           1  \n1           0  \n2           0  \n3           1  \n4           1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>review_text</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>786842</td>\n      <td>This is a special book. It started slow for ab...</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>583423</td>\n      <td>Recommended by Don Katz. Avail for free in Dec...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>165147</td>\n      <td>A fun, fast paced science fiction thriller. I ...</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>727692</td>\n      <td>Recommended reading to understand what is goin...</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>179941</td>\n      <td>I really enjoyed this book, and there is a lot...</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NLP**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=OOV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def get_sequences(tokenizer, review):\n",
    "    sequences = tokenizer.texts_to_sequences(review)\n",
    "    padded_sequences = pad_sequences(sequences, truncating='post', maxlen=MAX_SIZE, padding='post')\n",
    "    return padded_sequences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def tokenizer_func(data_rating, data_review):\n",
    "    tokenizer.fit_on_texts(data_review)\n",
    "\n",
    "    train_labels = data_rating.iloc[math.floor(int(len(data_rating) / 8)):]\n",
    "    train_examples = data_review.iloc[math.floor(int(len(data_review) / 8)):]\n",
    "    test_examples = data_review.iloc[:math.floor(int(len(data_review) / 8))]\n",
    "    test_labels = data_rating.iloc[:math.floor(int(len(data_rating) / 8))]\n",
    "\n",
    "    padded_train = get_sequences(tokenizer, train_examples)\n",
    "    padded_test = get_sequences(tokenizer, test_examples)\n",
    "\n",
    "    return np.array(padded_train), np.array(padded_test), np.array(train_labels), np.array(test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "padded_train, padded_test, train_labels, test_labels = tokenizer_func(y_train, x_train['review_text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "np.save('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/tokenizer_func/padded_train.npy', padded_train)\n",
    "np.save('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/tokenizer_func/padded_test.npy', padded_test)\n",
    "np.save('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/tokenizer_func/train_labels.npy', train_labels)\n",
    "np.save('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/tokenizer_func/test_labels.npy', test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# padded_train = np.load('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/tokenizer_func/padded_train.npy')\n",
    "# padded_test = np.load('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/tokenizer_func/padded_test.npy')\n",
    "# train_labels = np.load('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/tokenizer_func/train_labels.npy')\n",
    "# test_labels = np.load('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/tokenizer_func/test_labels.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([  4,  12, 294,  16,   6,   1, 566,  31,   3,   9,  10, 456,  42,\n         4, 151,  88, 597,   1,  59,  10,   6,   1,   7,   6,   1,   1,\n        21,  10, 635,  16,   2,   1,   1, 459,  45,  34, 185,   1,  27,\n         6, 428,   5,   1,   2, 223,   7,   2, 888,   1,   1, 388,  42,\n        80,   4, 134,  47,   1, 362,   3, 566,  32,  42,   4,  12, 294,\n        16,   4,  91,  37, 291,  13,  14,  15,   9, 167, 209, 124, 207,\n        25, 132,  48, 156, 290,   3,  84,   1, 255, 111, 383, 242, 124,\n         3,  42, 180,   7, 460,  10,   1,   1,  24,   2, 434,  70, 914,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sarcasm detection**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "data = pd.read_json('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/sarcasm/Sarcasm_Headlines_Dataset.json', lines=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Iterating through the json data and loading the requisite values into our python lists\n",
    "sentences = data['headline']\n",
    "labels = data['is_sarcastic']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "training_sentences = sentences[0:SARCASM_TRAINING_SIZE]\n",
    "testing_sentences = sentences[SARCASM_TRAINING_SIZE:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "training_labels = labels[0:SARCASM_TRAINING_SIZE]\n",
    "testing_labels = labels[SARCASM_TRAINING_SIZE:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(training_sentences)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Creating training sequences and padding them\n",
    "training_padded = get_sequences(tokenizer, training_sentences)\n",
    "testing_padded = get_sequences(tokenizer, testing_sentences)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Converting all variables to numpy arrays, to be able to work with tf version 2\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Creating a model for sentiment analysis\n",
    "sarcasm_model = tf.keras.Sequential([\n",
    "    # Adding an Embedding layer for Neural Network to learn the vectors\n",
    "    tf.keras.layers.Embedding(NUM_WORDS, EMBEDDING_DIM, input_length=MAX_SIZE),\n",
    "    # Global Average pooling is similar to adding up vectors in this case\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "sarcasm_model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 5s 6ms/step - loss: 0.6857 - accuracy: 0.5599 - val_loss: 0.6835 - val_accuracy: 0.5633\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.6795 - accuracy: 0.5603 - val_loss: 0.6639 - val_accuracy: 0.5654\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.6153 - accuracy: 0.6586 - val_loss: 0.5571 - val_accuracy: 0.7323\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.5211 - accuracy: 0.7438 - val_loss: 0.5040 - val_accuracy: 0.7478\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.4850 - accuracy: 0.7617 - val_loss: 0.4865 - val_accuracy: 0.7576\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.4711 - accuracy: 0.7703 - val_loss: 0.4831 - val_accuracy: 0.7597\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.4648 - accuracy: 0.7705 - val_loss: 0.4774 - val_accuracy: 0.7633\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.4605 - accuracy: 0.7750 - val_loss: 0.4742 - val_accuracy: 0.7670\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.4558 - accuracy: 0.7775 - val_loss: 0.4713 - val_accuracy: 0.7672\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.4515 - accuracy: 0.7788 - val_loss: 0.4730 - val_accuracy: 0.7697\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1bc9cee7b50>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_model.fit(training_padded, training_labels, epochs=EPOCHS,\n",
    "                    validation_data=(testing_padded, testing_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24610/24610 [==============================] - 37s 2ms/step\n",
      "3516/3516 [==============================] - 5s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "sarcasm_prediction_train = sarcasm_model.predict(padded_train)\n",
    "sarcasm_prediction_test = sarcasm_model.predict(padded_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "np.save('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/sarcasm_model/sarcasm_prediction_train.npy', sarcasm_prediction_train)\n",
    "np.save('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/sarcasm_model/sarcasm_prediction_test.npy', sarcasm_prediction_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# sarcasm_prediction_train = np.load('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/sarcasm_model/sarcasm_prediction_train.npy')\n",
    "# sarcasm_prediction_test = np.load('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/sarcasm_model/sarcasm_prediction_test.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reshaping data**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(787500, 1)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_prediction_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "(787500, 399)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "padded_train = np.concatenate((padded_train, np.array(sarcasm_prediction_train.flatten())[:, None]), axis=1)\n",
    "padded_test = np.concatenate((padded_test, np.array(sarcasm_prediction_test.flatten())[:, None]), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "(787500, 400)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "padded_train = np.reshape(padded_train, (1 - math.floor(len(y_train) / 8),int(math.sqrt(MAX_SIZE + 1)), int(math.sqrt(MAX_SIZE + 1))))\n",
    "padded_test = np.reshape(padded_test, (math.floor(int(len(x_train['review_text']) / 8)), int(math.sqrt(MAX_SIZE + 1)), int(math.sqrt(MAX_SIZE + 1))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# padded_train = np.reshape(padded_train, (1 - math.floor(int(len(label) / 8)), int(math.sqrt(MAX_SIZE + 1)), int(math.sqrt(MAX_SIZE + 1))))\n",
    "# padded_test = np.reshape(padded_test, (math.floor(int(len(label) / 8)), int(math.sqrt(MAX_SIZE + 1)), int(math.sqrt(MAX_SIZE + 1))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "(787500, 20, 20)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padded_train[0]\n",
    "padded_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "np.save('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/test0.npy', padded_train)\n",
    "np.save('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/test1.npy', padded_test)\n",
    "np.save('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/test2.npy', train_labels)\n",
    "np.save('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/test3.npy', test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# padded_train = np.load('C:/Users/tomcareghi/Documents/ESGI/4IABD/S1/Deep_Learning/DeepLearning4IABD/src/data/test.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# CNN\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(8, (3, 3), activation=tf.keras.activations.tanh, padding='same'))\n",
    "model.add(tf.keras.layers.Conv2D(8, (3, 3), activation=tf.keras.activations.tanh, padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.tanh, padding='same'))\n",
    "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.tanh, padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.tanh, padding='same'))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.tanh, padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "# model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.tanh, padding='same'))\n",
    "# model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.tanh, padding='same'))\n",
    "# model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(64, activation=tf.keras.activations.relu))  # tf.keras.activations.tanh\n",
    "model.add(tf.keras.layers.Dense(32, activation=tf.keras.activations.relu))  # tf.keras.activations.tanh\n",
    "model.add(tf.keras.layers.Dense(16, activation=tf.keras.activations.relu))  # tf.keras.activations.tanh\n",
    "model.add(tf.keras.layers.Dense(6,\n",
    "                                activation=tf.keras.activations.softmax))  # model.add(tf.keras.layers.Dense(1, activation=tf.keras.activations.softmax))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.1, momentum=0.1),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[1;32mIn [45]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m padded_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(padded_train, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      9\u001B[0m padded_test \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(padded_test, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadded_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensorBoard\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtensorboard\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/trash3/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpadded_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\n\u001B[0;32m     18\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[1;34m(value, ctx, dtype)\u001B[0m\n\u001B[0;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[0;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mInternalError\u001B[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "padded_train = padded_train / NUM_WORDS\n",
    "padded_test = padded_test / NUM_WORDS\n",
    "# print(padded_train.shape)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, 6)\n",
    "# print(padded_train.shape)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 6)\n",
    "\n",
    "padded_train = np.expand_dims(padded_train, -1)\n",
    "padded_test = np.expand_dims(padded_test, -1)\n",
    "model.fit(\n",
    "    # padded_train, donner un dataset avec .batch_size tfrecord\n",
    "    # train_labels,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard\" + \"/trash3/\")],\n",
    "    validation_data=(padded_test, test_labels),\n",
    "    verbose=1,\n",
    "    # batch_size=1024\n",
    ")\n",
    "# keras tuner"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
