{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Load Libs**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [],
   "source": [
    "# Native python libs\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import collections\n",
    "from datetime import datetime\n",
    "from typing import Any, Union\n",
    "\n",
    "import keras.optimizers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip installed libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Paths**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "BASE_PATH = f\"{os.path.abspath('')}\\\\..\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Kaggle**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "KAGGLE = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "KAGGLE_PATH = \"kaggle\" if KAGGLE else f\"{BASE_PATH}\\\\kaggle\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "def output_path_exists() -> str:\n",
    "    directory = f\"{KAGGLE_PATH}\\\\working\\\\{datetime.now().strftime('%d%m%Y')}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "        print(f\"Created new output directory for today at '{directory}'\")\n",
    "    return directory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "INPUT_PATH = f\"{KAGGLE_PATH}\\\\input\\\\goodreads-books-reviews-290312\"\n",
    "OUTPUT_PATH = f\"{output_path_exists()}\\\\{datetime.now().strftime('%H%M%S')}_submission.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Tensorboard**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "TENSORBOARD_LOGS_PATH = f\"{BASE_PATH}\\\\tensorboard_logs\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "# Machine Learning tensorboard paths\n",
    "TENSORBOARD_LOGS_PATH_ML = f\"{TENSORBOARD_LOGS_PATH}\\\\ML\"\n",
    "LINEAR = f\"{TENSORBOARD_LOGS_PATH_ML}\\\\Linear\"\n",
    "MLP = f\"{TENSORBOARD_LOGS_PATH_ML}\\\\MLP\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [],
   "source": [
    "# Deep Learning tensorboard paths\n",
    "TENSORBOARD_LOGS_PATH_DL = f\"{TENSORBOARD_LOGS_PATH}\\\\DL\"\n",
    "CNN = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\CNN\"\n",
    "RNN = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\RNN\"\n",
    "TRANSFORMER = f\"{TENSORBOARD_LOGS_PATH_DL}\\\\Transformer\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\juanm\\\\OneDrive\\\\Bureau\\\\ESGI - Projets\\\\4IABD\\\\Projet Deep Learning\\\\tensorboard_logs'"
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if path is good\n",
    "os.path.abspath(TENSORBOARD_LOGS_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hyperparameters**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [],
   "source": [
    "# Fix\n",
    "CLASSES = 6\n",
    "BATCH_SIZE = 32  # Train = 900000 | Test = 478033\n",
    "BUFFER = 50000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "# Adjustable\n",
    "VOCAB_SIZE = 20000\n",
    "SEQUENCE_LENGTH = 256\n",
    "EMBEDDING_DIMS = 128\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_HEADS = 2\n",
    "FF_DIMS = 4 * EMBEDDING_DIMS  # In paper, value used is 4 * EMBEDDING_DIMS\n",
    "DROPOUT_RATE = 0  # Between 0 and 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load Data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "def load_csv_data(path: str,\n",
    "                  batch_size: int = BATCH_SIZE,\n",
    "                  buffer: int = BUFFER,\n",
    "                  separator: Union[list[str], str] = ',',\n",
    "                  columns: list[str] = None) -> collections.OrderedDict:\n",
    "    # Load data -> tensors\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        path,\n",
    "        batch_size=batch_size,\n",
    "        field_delim=separator,\n",
    "        select_columns=columns,\n",
    "        shuffle=False,\n",
    "        prefetch_buffer_size=buffer,\n",
    "        num_rows_for_inference=None\n",
    "    )\n",
    "    # Get an iterator over the dataset\n",
    "    iterator = dataset.as_numpy_iterator()\n",
    "    return next(iterator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Train Dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 57.8 s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load training dataset\n",
    "train_dataset = load_csv_data(f\"{INPUT_PATH}\\\\goodreads_train.csv\",\n",
    "                              batch_size=900000,\n",
    "                              columns=['review_text', 'rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [],
   "source": [
    "train_ratings = train_dataset['rating']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Test Dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 35.3 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load test dataset\n",
    "test_dataset = load_csv_data(f\"{INPUT_PATH}\\\\goodreads_test.csv\",\n",
    "                             batch_size=1024,\n",
    "                             columns=['review_id', 'review_text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [],
   "source": [
    "test_review_ids = test_dataset['review_id']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NLP**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "# Create a TextVectorization layer\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(standardize=None,\n",
    "                                                    output_sequence_length=SEQUENCE_LENGTH,\n",
    "                                                    output_mode='int')  # int avec couche d'embedding sinon tf_idf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 57s\n",
      "Wall time: 6min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the layer to the input text data\n",
    "vectorize_layer.adapt(train_dataset['review_text'], batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n '[UNK]',\n 'the',\n 'and',\n 'I',\n 'to',\n 'a',\n 'of',\n 'is',\n 'was',\n 'in',\n 'that',\n 'it',\n 'this',\n 'for',\n 'but',\n 'with',\n 'book',\n 'her',\n 'as',\n 'The',\n 'so',\n 'not',\n 'she',\n 'have',\n 'be',\n 'on',\n 'you',\n 'like',\n 'just',\n 'my',\n 'about',\n 'are',\n 'really',\n 'he',\n 'me',\n 'at',\n 'his',\n 'read',\n 'all',\n 'one',\n 'more',\n 'from',\n 'they',\n 'what',\n 'an',\n 'story',\n 'love',\n 'has',\n 'had',\n 'how',\n 'It',\n 'This',\n 'who',\n 'because',\n 'out',\n 'up',\n 'or',\n 'by',\n 'when',\n 'were',\n \"I'm\",\n 'would',\n 'their',\n 'much',\n 'some',\n 'get',\n \"didn't\",\n 'very',\n 'if',\n '-',\n 'there',\n 'characters',\n 'will',\n 'into',\n 'can',\n \"it's\",\n 'even',\n 'think',\n 'first',\n 'And',\n \"don't\",\n 'than',\n 'But',\n 'know',\n 'book.',\n 'also',\n 'been',\n 'it.',\n 'other',\n 'loved',\n 'only',\n 'good',\n 'reading',\n 'time',\n 'see',\n 'did',\n 'way',\n 'we',\n 'him',\n 'could',\n 'them',\n 'no',\n 'which',\n 'little',\n 'do',\n 'still',\n 'going',\n 'being',\n 'books',\n 'She',\n 'things',\n 'too',\n 'felt',\n \"It's\",\n 'made',\n 'feel',\n 'want',\n 'liked',\n 'series',\n 'never',\n 'book,',\n 'lot',\n 'character',\n 'people',\n 'make',\n 'after',\n 'where',\n 'two',\n 'then',\n 'bit',\n \"wasn't\",\n \"can't\",\n 'most',\n 'There',\n 'something',\n 'many',\n 'He',\n 'through',\n 'got',\n 'great',\n 'between',\n 'A',\n 'world',\n 'say',\n 'me.',\n 'am',\n 'thought',\n 'end',\n 'over',\n 'find',\n \"I've\",\n 'any',\n \"doesn't\",\n 'these',\n 'enjoyed',\n 'life',\n 'your',\n 'back',\n 'well',\n 'each',\n 'found',\n 'plot',\n 'while',\n 'go',\n 'new',\n 'those',\n 'writing',\n 'though',\n 'always',\n 'next',\n 'In',\n 'thing',\n 'kind',\n 'why',\n 'story.',\n 'actually',\n 'pretty',\n 'So',\n 'few',\n 'off',\n 'definitely',\n 'does',\n 'both',\n 'such',\n 'best',\n 'wanted',\n 'every',\n 'it,',\n 'makes',\n 'part',\n 'quite',\n 'If',\n 'whole',\n 'different',\n 'main',\n 'novel',\n 'everything',\n 'own',\n 'author',\n 'interesting',\n 'give',\n 'last',\n 'right',\n 'sure',\n 'better',\n 'before',\n 'same',\n 'its',\n \"she's\",\n \"that's\",\n 'enough',\n 'ever',\n 'take',\n 'romance',\n 'They',\n 'now',\n 'come',\n 'should',\n \"isn't\",\n 'What',\n 'hard',\n 'since',\n 'put',\n \"couldn't\",\n 'around',\n 'ending',\n 'review',\n 'relationship',\n 'down',\n 'another',\n 'read.',\n 'i',\n 'her.',\n 'without',\n 'long',\n 'You',\n 'series.',\n 'As',\n 'bad',\n 'need',\n \"he's\",\n 'until',\n 'real',\n '(hide',\n 'might',\n 'stars',\n 'keep',\n 'left',\n '(view',\n 'second',\n 'favorite',\n 'me,',\n 'anything',\n 'girl',\n 'them.',\n 'When',\n 'start',\n 'My',\n 'That',\n \"I'd\",\n 'point',\n 'started',\n 'family',\n 'trying',\n 'him.',\n 'may',\n 'wait',\n 'almost',\n 'probably',\n 'away',\n 'someone',\n 'story,',\n 'Not',\n 'getting',\n 'our',\n 'myself',\n 'years',\n 'times',\n \"I'll\",\n 'spoiler)]',\n 'nothing',\n 'fact',\n 'enjoy',\n 'help',\n 'especially',\n 'seems',\n 'completely',\n 'took',\n 'seemed',\n 'having',\n 'written',\n 'understand',\n 'characters.',\n 'looking',\n 'gets',\n 'fun',\n 'work',\n \"there's\",\n 'us',\n 'comes',\n 'together',\n 'one.',\n 'kept',\n 'heart',\n 'We',\n 'big',\n 'recommend',\n 'let',\n 'For',\n 'knew',\n 'characters,',\n 'everyone',\n 'able',\n \"you're\",\n 'person',\n 'man',\n 'finally',\n 'came',\n 'once',\n 'stories',\n 'tell',\n 'happy',\n 'that.',\n 'look',\n 'yet',\n 'old',\n 'went',\n 'full',\n 'All',\n 'young',\n 'least',\n 'past',\n 'perfect',\n 'happened',\n 'far',\n 'rather',\n 'time.',\n 'maybe',\n 'series,',\n 'idea',\n 'takes',\n 'set',\n 'One',\n 'pages',\n 'absolutely',\n 'believe',\n 'seem',\n 'three',\n 'hope',\n 'However,',\n 'place',\n 'friends',\n 'strong',\n 'herself',\n 'here',\n 'said',\n 'care',\n 'amazing',\n 'done',\n 'While',\n 'Her',\n 'already',\n 'wants',\n 'told',\n 'less',\n 'feeling',\n '&',\n 'beginning',\n 'high',\n 'must',\n 'that,',\n '5',\n 'wish',\n 'At',\n 'half',\n 'sense',\n 'totally',\n 'glad',\n 'beautiful',\n 'Even',\n '--',\n '.',\n 'life.',\n 'again',\n 'reason',\n 'her,',\n 'goes',\n 'easy',\n 'feels',\n 'end.',\n 'become',\n 'mind',\n 'nice',\n 'books.',\n 'YA',\n 'forward',\n 'well.',\n 'making',\n \"won't\",\n 'hate',\n 'couple',\n 'all.',\n 'reader',\n 'After',\n 'guy',\n 'truly',\n 'mean',\n 'parts',\n 'anyone',\n 'entire',\n \"She's\",\n 'more.',\n 'rest',\n 'day',\n 'gave',\n 'knows',\n 'school',\n 'live',\n 'year',\n 'friend',\n \"wouldn't\",\n 'way.',\n 'used',\n 'short',\n 'action',\n 'sort',\n 'feelings',\n 'sex',\n 'try',\n 'coming',\n 'read,',\n 'scenes',\n 'this.',\n 'along',\n 'out.',\n 'happens',\n \"There's\",\n 'side',\n 'fantasy',\n '(and',\n 'job',\n 'write',\n 'throughout',\n 'stop',\n 'woman',\n 'guess',\n \"He's\",\n \"they're\",\n 'seeing',\n 'fan',\n 'given',\n 'thinking',\n '4',\n 'mystery',\n 'lost',\n 'exactly',\n 'happen',\n 'else',\n 'all,',\n 'true',\n 'boy',\n 'finished',\n 'stars.',\n 'sometimes',\n '3',\n 'up.',\n 'him,',\n 'character.',\n 'novel.',\n 'To',\n 'time,',\n 'fall',\n 'Just',\n 'mother',\n '**',\n 'doing',\n 'worth',\n 'remember',\n 'sweet',\n 'books,',\n 'although',\n 'instead',\n 'lives',\n 'learn',\n 'readers',\n 'father',\n 'ended',\n 'change',\n 'dark',\n 'again.',\n 'needed',\n 'course',\n 'Then',\n 'human',\n 'during',\n 'Also,',\n 'honest',\n 'saw',\n 'head',\n 'end,',\n 'much.',\n 'this,',\n 'Maybe',\n 'good.',\n 'too.',\n 'is,',\n 'seen',\n 'though,',\n 'often',\n 'against',\n 'His',\n 'page',\n 'pick',\n 'issues',\n 'moments',\n 'one,',\n 'others',\n 'starts',\n 'How',\n 'emotional',\n 'them,',\n 'wonderful',\n 'style',\n 'words',\n 'on.',\n 'giving',\n 'use',\n 'previous',\n 'despite',\n 'slow',\n 'world.',\n 'Now',\n 'scene',\n 'character,',\n 'magic',\n 'needs',\n 'problem',\n 'finds',\n 'important',\n \"haven't\",\n \"That's\",\n '\"I',\n 'finish',\n 'huge',\n 'leave',\n 'himself',\n 'spoiler)[',\n 'cannot',\n '2',\n 'turn',\n 'show',\n 'supposed',\n 'turned',\n 'No',\n 'third',\n 'female',\n 'funny',\n 'reviews',\n 'sad',\n 'is.',\n 'talk',\n 'THE',\n 'certain',\n 'women',\n 'Like',\n 'fell',\n '3.5',\n 'wrong',\n 'small',\n 'well,',\n 'you.',\n 'hot',\n 'With',\n 'Overall,',\n 'expect',\n 'towards',\n 'Some',\n 'movie',\n 'became',\n 'novel,',\n 'moment',\n 'simply',\n 'life,',\n 'behind',\n 'together.',\n 'Book',\n 'star',\n 'On',\n '(I',\n 'home',\n 'several',\n 'interested',\n 'living',\n 'Because',\n 'surprised',\n 'down.',\n 'matter',\n 'love.',\n 'excited',\n 'decided',\n 'deal',\n 'turns',\n 'expected',\n 'future',\n 'super',\n 'eyes',\n 'unique',\n 'death',\n 'mostly',\n 'parents',\n 'events',\n ':)',\n 'said,',\n 'figure',\n 'middle',\n \"aren't\",\n 'So,',\n 'heroine',\n 'usually',\n 'picked',\n 'certainly',\n 'it!',\n 'girls',\n 'name',\n 'saying',\n 'there.',\n 'close',\n 'other.',\n 'either',\n 'later',\n 'meet',\n 'did.',\n 'though.',\n 'difficult',\n 'final',\n 'book!',\n 'chapters',\n 'highly',\n 'soon',\n 'again,',\n 'face',\n 'becomes',\n 'under',\n 'here.',\n 'ends',\n 'you,',\n 'honestly',\n 'extremely',\n 'mean,',\n 'way,',\n 'continue',\n 'romantic',\n 'crazy',\n 'single',\n 'ending.',\n 'Why',\n 'copy',\n 'review.',\n 'chapter',\n 'now.',\n 'fast',\n 'gives',\n 'experience',\n 'novels',\n 'awesome',\n 'heard',\n 'taking',\n 'taken',\n 'overall',\n 'be.',\n 'stand',\n 'stuff',\n '4.5',\n 'kill',\n 'within',\n 'love,',\n 'stay',\n 'men',\n 'called',\n 'means',\n 'wanting',\n 'interest',\n 'better.',\n 'expecting',\n 'line',\n 'meets',\n 'cover',\n 'particularly',\n 'brother',\n 'in.',\n 'original',\n 'course,',\n 'waiting',\n 'sister',\n 'quickly',\n 'across',\n 'incredibly',\n 'quick',\n 'save',\n 'type',\n 'light',\n 'Of',\n 'spoiler',\n 'history',\n 'realize',\n 'Although',\n 'move',\n 'good,',\n 'development',\n 'Oh',\n 'world,',\n 'four',\n 'admit',\n 'brought',\n 'basically',\n 'Well,',\n 'adult',\n 'case',\n 'up,',\n 'loves',\n 'chance',\n 'setting',\n 'twists',\n 'play',\n 'out,',\n 'whether',\n 'hoping',\n 'power',\n 'fight',\n 'five',\n 'disappointed',\n 'enjoyable',\n 'easily',\n 'Will',\n 'night',\n 'cute',\n 'talking',\n 'fantastic',\n 'order',\n 'works',\n 'tale',\n 'tried',\n 'Yes,',\n 'clear',\n 'Review',\n 'twist',\n 'First',\n 'thoughts',\n 'New',\n \"what's\",\n 'major',\n 'lack',\n 'weird',\n 'Harry',\n 'hero',\n 'itself',\n 'hated',\n 'ones',\n 'shows',\n 'fiction',\n 'personal',\n 'building',\n '...',\n 'kids',\n 'word',\n 'finding',\n 'historical',\n 'actual',\n 'favourite',\n 'days',\n 'telling',\n 'keeps',\n 'hell',\n 'romance.',\n 'Read',\n 'follow',\n 'emotions',\n 'knowing',\n 'journey',\n 'on,',\n 'ways',\n \"you'll\",\n 'was.',\n 'times.',\n 'top',\n 'romance,',\n 'based',\n 'group',\n 'male',\n 'questions',\n 'lots',\n 'bring',\n \"weren't\",\n 'These',\n 'Their',\n 'problems',\n 'to.',\n 'call',\n 'reading.',\n 'interesting.',\n 'sexy',\n 'complete',\n 'about.',\n 'exchange',\n 'break',\n 'know,',\n 'worked',\n 'times,',\n 'authors',\n 'spent',\n 'voice',\n 'points',\n 'known',\n 'mention',\n 'tells',\n 'Or',\n 'literally',\n 'town',\n 'From',\n 'friendship',\n 'age',\n 'similar',\n 'says',\n 'trust',\n 'forced',\n 'due',\n 'evil',\n 'watching',\n 'deep',\n 'except',\n 'focus',\n 'annoying',\n 'relationships',\n 'hold',\n 'early',\n 'somewhat',\n 'sexual',\n 'details',\n 'themselves',\n 'run',\n 'guys',\n 'Another',\n 'children',\n 'SO',\n 'met',\n 'inside',\n 'rating',\n 'magical',\n 'wonder',\n 'meant',\n 'however,',\n 'working',\n 'connection',\n 'amount',\n 'seriously',\n 'now,',\n 'free',\n 'But,',\n 'longer',\n 'plot.',\n 'view',\n \"Don't\",\n 'realistic',\n 'war',\n 'secret',\n 'thinks',\n 'changed',\n 'killed',\n 'drama',\n 'situation',\n 'beyond',\n 'elements',\n 'open',\n 'fully',\n 'say,',\n 'thing.',\n 'reminded',\n 'fact,',\n 'obvious',\n 'grow',\n 'attention',\n 'Love',\n 'AND',\n '\"The',\n 'appreciate',\n 'starting',\n 'tries',\n 'slightly',\n 'away.',\n 'alert',\n 'immediately',\n 'grew',\n 'imagine',\n 'lead',\n '(which',\n \"you've\",\n 'people.',\n 'received',\n 'hands',\n 'hit',\n 'typical',\n 'added',\n 'loving',\n 'first,',\n 'missing',\n 'strange',\n 'premise',\n 'boring',\n 'plot,',\n 'dead',\n 'fit',\n 'serious',\n 'really,',\n 'developed',\n 'Is',\n 'there,',\n 'somehow',\n 'filled',\n '(or',\n 'created',\n 'issue',\n 'Stars',\n 'not.',\n 'entirely',\n 'with.',\n 'version',\n 'child',\n 'mentioned',\n 'powerful',\n 'cool',\n 'Ms.',\n 'present',\n 'Which',\n 'constantly',\n 'hurt',\n 'complex',\n 'upon',\n 'special',\n 'was,',\n 'Though',\n 'ready',\n 'slowly',\n 'information',\n 'sequel',\n 'King',\n 'entertaining',\n 'annoyed',\n 'nearly',\n 'interesting,',\n 'concept',\n 'together,',\n 'happening',\n 'house',\n 'clearly',\n 'aspect',\n 'storyline',\n 'do.',\n 'normal',\n 'realized',\n 'wrote',\n 'alone',\n 'add',\n 'leaves',\n 'falling',\n 'Loved',\n 'whose',\n 'begins',\n 'perhaps',\n 'kinda',\n 'hear',\n 'Once',\n '*',\n '(the',\n 'mysterious',\n 'stupid',\n 'older',\n 'Kate',\n 'heart.',\n 'society',\n 'excellent',\n 'drawn',\n 'great.',\n 'question',\n 'okay',\n 'gone',\n 'An',\n 'writes',\n 'here,',\n 'fairly',\n 'Also',\n 'willing',\n 'amazing.',\n 'Overall',\n 'narrative',\n 'near',\n 'Every',\n 'begin',\n 'things.',\n 'family.',\n ...]"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [],
   "source": [
    "def vectorize_text(text: Any, label: Any) -> Any:\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Creating Dataset For Models**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "def dataset_from_raw_data(x: np.ndarray, y: np.ndarray, batch_size: int = BATCH_SIZE) -> Any:\n",
    "    y = tf.keras.utils.to_categorical(y, dtype='int32')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))#.batch(batch_size)\n",
    "    dataset = dataset.map(vectorize_text)\n",
    "    print(dataset)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), TensorSpec(shape=(6,), dtype=tf.int32, name=None))>\n",
      "CPU times: total: 2 s\n",
      "Wall time: 8.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = dataset_from_raw_data(train_dataset['review_text'], train_dataset['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Linear**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "def linear(hp):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(CLASSES, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**MLP**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "def mlp(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(CLASSES, activation='sigmoid'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**CNN**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "# CNN init\n",
    "def cnn(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int32))\n",
    "    model.add(tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS))\n",
    "    model.add(tf.keras.layers.Reshape((math.isqrt(SEQUENCE_LENGTH), math.isqrt(SEQUENCE_LENGTH), -1),\n",
    "                                      input_shape=(None, SEQUENCE_LENGTH)))\n",
    "    # Conv & pooling layers\n",
    "    hp_filters_1 = hp.Int('filters', min_value=8, max_value=32, step=8)\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_1, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_1, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    hp_filters_2 = hp.Int('filters', min_value=16, max_value=64, step=16)\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_2, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_2, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    hp_filters_3 = hp.Int('filters', min_value=32, max_value=128, step=32)\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_3, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_3, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    hp_filters_4 = hp.Int('filters', min_value=64, max_value=256, step=64)\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_4, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=hp_filters_4, kernel_size=(3, 3), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    # Fully connected layers\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    hp_units_1 = hp.Int('units', min_value=64, max_value=256, step=64)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units_1, activation='relu'))\n",
    "    hp_units_2 = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units_2, activation='relu'))\n",
    "    hp_units_3 = hp.Int('units', min_value=16, max_value=64, step=16)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units_3, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(CLASSES, activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**ResNets / HighwayNets**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**RNN**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Transformer**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "\n",
    "x = tf.keras.layers.Embedding(VOCAB_SIZE + 1, EMBEDDING_DIMS)(inputs)\n",
    "\n",
    "# Add the multi-head self-attention layer\n",
    "x = tf.keras.layers.MultiHeadAttention(EMBEDDING_DIMS, NUM_HEADS)(x, x, x)\n",
    "# Regularization\n",
    "x = tf.keras.layers.Dropout(rate=DROPOUT_RATE)(x)\n",
    "# Add the feed-forward layer\n",
    "x = tf.keras.layers.Dense(FF_DIMS, activation='relu')(x)\n",
    "# Regularization\n",
    "x = tf.keras.layers.Dropout(rate=DROPOUT_RATE)(x)\n",
    "\n",
    "# Add a dense layer for output\n",
    "outputs = tf.keras.layers.Dense(VOCAB_SIZE + 1)(x)\n",
    "\n",
    "# Create the model\n",
    "transformer = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "'class TransformerBlock(tf.keras.layers.Layer):\\n    def __init__(self,\\n                 num_heads: int = NUM_HEADS,\\n                 ff_dim: int = FF_DIMS,\\n                 embed_dim: int = EMBEDDING_DIMS,\\n                 dropout_rate: int = 0):\\n        # TODO : NUM_HEADS HV A IMPLEMENTER\\n        super().__init__()\\n        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\\n        self.ffn = tf.keras.Sequential(\\n            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\\n             tf.keras.layers.Dense(embed_dim),]\\n        )\\n        self.layer_norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\\n        self.layer_norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\\n        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\\n        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\\n\\n    def call(self, inputs, training):\\n        attn_output = self.att(inputs, inputs)\\n        attn_output = self.dropout1(attn_output, training=training)\\n        out1 = self.layernorm1(inputs + attn_output)\\n        ffn_output = self.ffn(out1)\\n        ffn_output = self.dropout2(ffn_output, training=training)\\n        return self.layernorm2(out1 + ffn_output)'"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_heads: int = NUM_HEADS,\n",
    "                 ff_dim: int = FF_DIMS,\n",
    "                 embed_dim: int = EMBEDDING_DIMS,\n",
    "                 dropout_rate: int = 0):\n",
    "        # TODO : NUM_HEADS HV A IMPLEMENTER\n",
    "        super().__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layer_norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "'class TokenAndPositionEmbedding(tf.keras.layers.Layer):\\n    def __init__(self,\\n                 maxlen: int = SEQUENCE_LENGTH,\\n                 vocab_size: int = VOCAB_SIZE,\\n                 embed_dim: int = EMBEDDING_DIMS):\\n        super().__init__()\\n        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\\n        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\\n\\n    def call(self, dataset):\\n        maxlen = tf.shape(dataset)[-1]\\n        positions = tf.range(start=0, limit=maxlen, delta=1)\\n        positions = self.pos_emb(positions)\\n        dataset = self.token_emb(dataset)\\n        return dataset + positions'"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 maxlen: int = SEQUENCE_LENGTH,\n",
    "                 vocab_size: int = VOCAB_SIZE,\n",
    "                 embed_dim: int = EMBEDDING_DIMS):\n",
    "        super().__init__()\n",
    "        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, dataset):\n",
    "        maxlen = tf.shape(dataset)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        dataset = self.token_emb(dataset)\n",
    "        return dataset + positions\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "'inputs = tf.keras.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int64)\\nembedding_layer = TokenAndPositionEmbedding()\\ntransformer = embedding_layer(inputs)\\ntransformer_block = TransformerBlock(transformer)\\ntransformer = transformer_block(transformer)\\ntransformer = tf.keras.layers.GlobalAveragePooling1D()(transformer)\\ntransformer = tf.keras.layers.Dense(20, activation=\"relu\")(transformer)\\noutputs = tf.keras.layers.Dense(CLASSES, activation=\"softmax\")(transformer)\\n\\ntransformer = tf.keras.Model(inputs=inputs, outputs=outputs)'"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"inputs = tf.keras.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int64)\n",
    "embedding_layer = TokenAndPositionEmbedding()\n",
    "transformer = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(transformer)\n",
    "transformer = transformer_block(transformer)\n",
    "transformer = tf.keras.layers.GlobalAveragePooling1D()(transformer)\n",
    "transformer = tf.keras.layers.Dense(20, activation=\"relu\")(transformer)\n",
    "outputs = tf.keras.layers.Dense(CLASSES, activation=\"softmax\")(transformer)\n",
    "\n",
    "transformer = tf.keras.Model(inputs=inputs, outputs=outputs)\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 256), dtype=tf.int64, name=None), TensorSpec(shape=(None, 6), dtype=tf.int32, name=None))>\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 98.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = dataset_from_raw_data(train_dataset['review_text'], train_dataset['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for data in train_dataset:\n",
    "    counter += 1\n",
    "print(counter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "'%%time\\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\\n\\nwith ThreadPoolExecutor() as executor:\\n    model_functions = [linear, mlp, cnn]\\n    logs = [LINEAR, MLP, CNN]\\n    futures = [executor.submit(train_over_model, model_function, log) for model_function in model_functions for log in logs]\\n\\n    for future in as_completed(futures):\\n        future.result()\\n        POUR LE RAPPORT'"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    model_functions = [linear, mlp, cnn]\n",
    "    logs = [LINEAR, MLP, CNN]\n",
    "    futures = [executor.submit(train_over_model, model_function, log) for model_function in model_functions for log in logs]\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        future.result()\n",
    "        POUR LE RAPPORT\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "models = [linear, mlp, cnn]\n",
    "paths = [LINEAR, MLP, CNN]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "<keras_tuner.engine.trial.Trial object at 0x00000210927CCAF0>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:14\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\4IABD_DL\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:200\u001B[0m, in \u001B[0;36mBaseTuner.search\u001B[1;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_create_trial()\n\u001B[1;32m--> 200\u001B[0m     trial \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moracle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtuner_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trial\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m trial_module\u001B[38;5;241m.\u001B[39mTrialStatus\u001B[38;5;241m.\u001B[39mSTOPPED:\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;66;03m# Oracle triggered exit.\u001B[39;00m\n\u001B[0;32m    203\u001B[0m         tf\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOracle triggered exit\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\4IABD_DL\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:104\u001B[0m, in \u001B[0;36msynchronized.<locals>.wrapped_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    102\u001B[0m     LOCKS[oracle]\u001B[38;5;241m.\u001B[39macquire()\n\u001B[0;32m    103\u001B[0m     THREADS[oracle] \u001B[38;5;241m=\u001B[39m thread_name\n\u001B[1;32m--> 104\u001B[0m ret_val \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m need_acquire:\n\u001B[0;32m    106\u001B[0m     THREADS[oracle] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\4IABD_DL\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:302\u001B[0m, in \u001B[0;36mOracle.create_trial\u001B[1;34m(self, tuner_id)\u001B[0m\n\u001B[0;32m    300\u001B[0m \u001B[38;5;66;03m# Pick the Trials waiting for retry first.\u001B[39;00m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retry_queue) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 302\u001B[0m     trial \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrials\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    303\u001B[0m     trial\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m trial_module\u001B[38;5;241m.\u001B[39mTrialStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mongoing_trials[tuner_id] \u001B[38;5;241m=\u001B[39m trial\n",
      "\u001B[1;31mKeyError\u001B[0m: <keras_tuner.engine.trial.Trial object at 0x00000210927CCAF0>"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trained_models = []\n",
    "\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    for model, path in zip(models, paths):\n",
    "        # Init model\n",
    "        tuner = kt.BayesianOptimization(model,\n",
    "                                        objective='val_accuracy',\n",
    "                                        max_trials=EPOCHS,\n",
    "                                        alpha=1e-4,\n",
    "                                        beta=2.6)\n",
    "        print(0)\n",
    "        tuner.search(train_dataset,\n",
    "                     epochs=EPOCHS,\n",
    "                     callbacks=[stop_early])\n",
    "        best_hps = tuner.get_best_hyperparameters(num_trials=EPOCHS)\n",
    "        print(best_hps)\n",
    "        model = tuner.hypermodel.build(best_hps)\n",
    "        # Train over model\n",
    "        history = model.fit(train_dataset,\n",
    "                            epochs=EPOCHS,\n",
    "                            callbacks=[tf.keras.callbacks.TensorBoard(f\"{path}\"\n",
    "                                                                      f\"_BS_{BATCH_SIZE}\"\n",
    "                                                                      f\"_MAXFEAT_{VOCAB_SIZE}\"\n",
    "                                                                      f\"_EMBEDDING_{EMBEDDING_DIMS}\"\n",
    "                                                                      f\"_SEQLEN_{SEQUENCE_LENGTH}\"\n",
    "                                                                      f\"_LR_{LEARNING_RATE}\")])\n",
    "        val_acc_per_epoch = history.history['val_accuracy']\n",
    "        best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "        print(f\"Best epoch: {best_epoch}\")\n",
    "        trained_models.append(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "data": {
      "text/plain": "[<keras.engine.sequential.Sequential at 0x134f7b7a140>,\n <keras.engine.sequential.Sequential at 0x134fbaf2c80>,\n <keras.engine.sequential.Sequential at 0x134ef70dde0>]"
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Computing Accuracy** _(To choose best algorithm for submission)_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "labels_predicted = 0  #[testing_model(trained_model, train_dataset) for trained_model in trained_models]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "data": {
      "text/plain": "32"
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_predicted[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for label in labels_predicted:\n",
    "    print(label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (1024,) and (3, 32) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [280]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m accuracy_metric \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mAccuracy()\n\u001B[1;32m----> 2\u001B[0m \u001B[43maccuracy_metric\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_ratings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_predicted\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(accuracy_metric\u001B[38;5;241m.\u001B[39mresult()\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\keras\\utils\\metrics_utils.py:77\u001B[0m, in \u001B[0;36mupdate_state_wrapper.<locals>.decorated\u001B[1;34m(metric_obj, *args, **kwargs)\u001B[0m\n\u001B[0;32m     69\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     70\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrying to run metric.update_state in replica context when \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     71\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe metric was not created in TPUStrategy scope. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     72\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMake sure the keras Metric is created in TPUstrategy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     73\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscope. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     74\u001B[0m         )\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf_utils\u001B[38;5;241m.\u001B[39mgraph_context_for_symbolic_tensors(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 77\u001B[0m     update_op \u001B[38;5;241m=\u001B[39m update_state_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m update_op \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# update_op will be None in eager execution.\u001B[39;00m\n\u001B[0;32m     79\u001B[0m     metric_obj\u001B[38;5;241m.\u001B[39madd_update(update_op)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\keras\\metrics\\base_metric.py:143\u001B[0m, in \u001B[0;36mMetric.__new__.<locals>.update_state_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    139\u001B[0m control_status \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mautograph\u001B[38;5;241m.\u001B[39mcontrol_status_ctx()\n\u001B[0;32m    140\u001B[0m ag_update_state \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mautograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[0;32m    141\u001B[0m     obj_update_state, control_status\n\u001B[0;32m    142\u001B[0m )\n\u001B[1;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ag_update_state(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    688\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[1;32m--> 689\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    691\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_in_allowlist_cache(f, options):\n\u001B[0;32m    330\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: from cache\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n\u001B[1;32m--> 331\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx()\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m ag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mDISABLED:\n\u001B[0;32m    334\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: AutoGraph is disabled in context\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[1;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[0;32m    455\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 458\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\keras\\metrics\\base_metric.py:700\u001B[0m, in \u001B[0;36mMeanMetricWrapper.update_state\u001B[1;34m(self, y_true, y_pred, sample_weight)\u001B[0m\n\u001B[0;32m    693\u001B[0m y_pred, y_true \u001B[38;5;241m=\u001B[39m losses_utils\u001B[38;5;241m.\u001B[39msqueeze_or_expand_dimensions(\n\u001B[0;32m    694\u001B[0m     y_pred, y_true\n\u001B[0;32m    695\u001B[0m )\n\u001B[0;32m    697\u001B[0m ag_fn \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mautograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[0;32m    698\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fn, tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mautograph\u001B[38;5;241m.\u001B[39mcontrol_status_ctx()\n\u001B[0;32m    699\u001B[0m )\n\u001B[1;32m--> 700\u001B[0m matches \u001B[38;5;241m=\u001B[39m ag_fn(y_true, y_pred, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fn_kwargs)\n\u001B[0;32m    701\u001B[0m mask \u001B[38;5;241m=\u001B[39m losses_utils\u001B[38;5;241m.\u001B[39mget_mask(matches)\n\u001B[0;32m    702\u001B[0m sample_weight \u001B[38;5;241m=\u001B[39m losses_utils\u001B[38;5;241m.\u001B[39mapply_valid_mask(\n\u001B[0;32m    703\u001B[0m     matches, sample_weight, mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction\n\u001B[0;32m    704\u001B[0m )\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    688\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[1;32m--> 689\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    691\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[1;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[1;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[0;32m    455\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 458\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\keras\\metrics\\metrics.py:3571\u001B[0m, in \u001B[0;36maccuracy\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m   3564\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maccuracy\u001B[39m(y_true, y_pred):\n\u001B[0;32m   3565\u001B[0m     [\n\u001B[0;32m   3566\u001B[0m         y_pred,\n\u001B[0;32m   3567\u001B[0m         y_true,\n\u001B[0;32m   3568\u001B[0m     ], _ \u001B[38;5;241m=\u001B[39m metrics_utils\u001B[38;5;241m.\u001B[39mragged_assert_compatible_and_get_flat_values(\n\u001B[0;32m   3569\u001B[0m         [y_pred, y_true]\n\u001B[0;32m   3570\u001B[0m     )\n\u001B[1;32m-> 3571\u001B[0m     \u001B[43my_true\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massert_is_compatible_with\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3572\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y_true\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m y_pred\u001B[38;5;241m.\u001B[39mdtype:\n\u001B[0;32m   3573\u001B[0m         y_pred \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcast(y_pred, y_true\u001B[38;5;241m.\u001B[39mdtype)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DeepLearning4IABD\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1307\u001B[0m, in \u001B[0;36mTensorShape.assert_is_compatible_with\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m   1295\u001B[0m \u001B[38;5;124;03m\"\"\"Raises exception if `self` and `other` do not represent the same shape.\u001B[39;00m\n\u001B[0;32m   1296\u001B[0m \n\u001B[0;32m   1297\u001B[0m \u001B[38;5;124;03mThis method can be used to assert that there exists a shape that both\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1304\u001B[0m \u001B[38;5;124;03m  ValueError: If `self` and `other` do not represent the same shape.\u001B[39;00m\n\u001B[0;32m   1305\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_compatible_with(other):\n\u001B[1;32m-> 1307\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShapes \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m are incompatible\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m, other))\n",
      "\u001B[1;31mValueError\u001B[0m: Shapes (1024,) and (3, 32) are incompatible"
     ]
    }
   ],
   "source": [
    "accuracy_metric = tf.keras.metrics.Accuracy()\n",
    "accuracy_metric.update_state(train_ratings, labels_predicted)\n",
    "print(accuracy_metric.result().numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Testing**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "test_dataset = dataset_from_raw_data(test_dataset['review_text'],\n",
    "                                     np.random.default_rng().integers(0, CLASSES, 1024))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def predict_model(model: tf.keras.Sequential, dataset: Any) -> np.ndarray:\n",
    "    model_predict = 0\n",
    "    for text, label in dataset:\n",
    "        model_predict = model.predict(text)\n",
    "    return model_predict.argmax(axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Submission**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Submission code\n",
    "sample_submission = pd.read_csv(INPUT_PATH + \"\\\\goodreads_sample_submission.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# Getting data for csv file\n",
    "sample_submission['rating'] = predict_model(cnn)\n",
    "sample_submission['review_id'] = [data.decode(\"utf-8\") for data in test_review_ids]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_submission.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"CSV registered at {OUTPUT_PATH}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
