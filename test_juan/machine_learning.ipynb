{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Load Libs**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1651,
   "outputs": [],
   "source": [
    "# Native python libs\n",
    "import os\n",
    "import collections"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1652,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip installed libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Paths**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1653,
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.abspath('') + \"\\\\..\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Kaggle**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "outputs": [],
   "source": [
    "KAGGLE_PATH = BASE_PATH + \"\\\\kaggle\"\n",
    "INPUT_PATH = KAGGLE_PATH + \"\\\\input\\\\goodreads-books-reviews-290312\"\n",
    "OUTPUT_PATH = KAGGLE_PATH + \"\\\\working\\\\submission.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Tensorboard**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1655,
   "outputs": [],
   "source": [
    "TENSORBOARD_LOGS_PATH = BASE_PATH + \"\\\\tensorboard_logs\"\n",
    "TENSORBOARD_LOGS_PATH_ML = TENSORBOARD_LOGS_PATH + \"\\\\ML\"\n",
    "TENSORBOARD_LOGS_PATH_DL = TENSORBOARD_LOGS_PATH + \"\\\\DL\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1656,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\juanm\\\\OneDrive\\\\Bureau\\\\ESGI - Projets\\\\4IABD\\\\Projet Deep Learning\\\\tensorboard_logs'"
     },
     "execution_count": 1656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if path is good\n",
    "os.path.abspath(TENSORBOARD_LOGS_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1658,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {TENSORBOARD_LOGS_PATH}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hyperparameters**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1659,
   "outputs": [],
   "source": [
    "CLASSES = 6\n",
    "BATCH_SIZE = 1024 # Size of csv file = 478033\n",
    "MAX_FEATURES = 20000\n",
    "EMBEDDING_DIM = 128\n",
    "SEQUENCE_LENGTH = 250\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load Data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1660,
   "outputs": [],
   "source": [
    "from typing import Any, Union\n",
    "\n",
    "\n",
    "def load_csv_data(path: str,\n",
    "                  batch_size: int = BATCH_SIZE,\n",
    "                  separator: Union[list[str], str] = ',',\n",
    "                  columns: Union[list[str], str] = None) -> collections.OrderedDict:\n",
    "    # Load data -> tensors\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        path,\n",
    "        batch_size=batch_size,\n",
    "        field_delim=separator,\n",
    "        select_columns=columns,\n",
    "        shuffle=False\n",
    "    )\n",
    "    # Get an iterator over the dataset\n",
    "    iterator = dataset.as_numpy_iterator()\n",
    "    return next(iterator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Train Dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1661,
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "train_dataset = load_csv_data(f\"{INPUT_PATH}\\\\goodreads_train.csv\", columns=['review_text', 'rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Test Dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1662,
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = load_csv_data(f\"{INPUT_PATH}\\\\goodreads_test.csv\", batch_size=478033, columns=['review_id', 'review_text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1663,
   "outputs": [],
   "source": [
    "test_review_ids = test_dataset['review_id']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NLP**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1664,
   "outputs": [],
   "source": [
    "# Create a TextVectorization layer\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(standardize=None,\n",
    "                                                    output_sequence_length=SEQUENCE_LENGTH,\n",
    "                                                    output_mode='int')  # Ou int avec couche d'embedding sinon tf_idf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1665,
   "outputs": [],
   "source": [
    "# Fit the layer to the input text data\n",
    "vectorize_layer.adapt(train_dataset['review_text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1666,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n '[UNK]',\n 'the',\n 'and',\n 'a',\n 'I',\n 'to',\n 'is',\n 'of',\n 'in',\n 'this',\n 'that',\n 'was',\n 'for',\n 'with',\n 'book',\n 'it',\n 'her',\n 'but',\n 'you',\n 'The',\n 'my',\n 'are',\n 'an',\n 'very',\n 'story',\n 'not',\n 'be',\n 'as',\n 'have',\n 'his',\n 'he',\n 'she',\n 'from',\n 'on',\n 'has',\n 'about',\n 'one',\n 'love',\n 'read',\n 'by',\n 'me',\n 'all',\n 'This',\n 'at',\n 'so',\n 'just',\n 'who',\n 'like',\n 'will',\n 'really',\n 'more',\n 'loved',\n 'author',\n 'they',\n 'what',\n 'characters',\n 'And',\n 'had',\n 'their',\n 'It',\n 'when',\n 'up',\n 'first',\n 'some',\n 'how',\n 'But',\n 'were',\n '-',\n 'He',\n 'would',\n 'there',\n 'into',\n 'can',\n 'absolutely',\n 'book.',\n 'much',\n 'out',\n 'sexy',\n 'or',\n 'could',\n 'honest',\n 'books',\n 'She',\n 'because',\n \"can't\",\n 'story.',\n 'provided',\n 'if',\n 'even',\n 'two',\n 'other',\n 'There',\n 'no',\n 'get',\n 'also',\n 'reading',\n 'know',\n \"I'm\",\n 'him',\n 'your',\n 'want',\n 'think',\n 'been',\n 'than',\n 'only',\n \"don't\",\n 'return',\n 'did',\n 'between',\n 'life',\n 'we',\n 'which',\n \"didn't\",\n 'am',\n 'then',\n 'after',\n 'do',\n 'never',\n 'review.)',\n 'series',\n 'romance',\n 'see',\n 'it.',\n 'make',\n 'most',\n '(ARC',\n 'both',\n 'these',\n 'favorite',\n 'A',\n 'way',\n 'scenes',\n 'each',\n 'time',\n 'wait',\n \"it's\",\n 'felt',\n 'every',\n 'always',\n 'through',\n 'good',\n 'writing',\n 'little',\n 'still',\n 'many',\n 'sex',\n 'heart',\n 'say',\n 'right',\n 'Ms.',\n 'ever',\n 'me.',\n 'book,',\n '4.5',\n 'where',\n 'hot',\n 'great',\n 'them',\n 'feel',\n 'off',\n 'You',\n '\"I',\n 'new',\n 'incredibly',\n 'If',\n 'back',\n 'perfect',\n 'made',\n 'best',\n 'too',\n 'kind',\n 'give',\n 'sexy,',\n \"doesn't\",\n 'over',\n 'being',\n 'plot',\n 'own',\n 'beautiful',\n 'away',\n 'does',\n 'going',\n 'written',\n 'put',\n 'any',\n 'almost',\n 'relationship',\n 'people',\n 'might',\n 'another',\n 'years',\n 'story,',\n 'lots',\n 'end',\n 'ending',\n 'let',\n 'until',\n 'though',\n 'recommend',\n 'next',\n 'things',\n 'need',\n 'makes',\n 'funny',\n 'What',\n 'totally',\n 'part',\n 'completely',\n 'character',\n 'go',\n 'wanted',\n 'thought',\n 'our',\n 'everything',\n 'while',\n 'take',\n 'something',\n 'find',\n 'characters.',\n 'They',\n 'actually',\n 'well',\n 'life.',\n 'emotional',\n \"wasn't\",\n 'pretty',\n 'times',\n 'lot',\n 'read.',\n 'family',\n 'world',\n 'main',\n 'My',\n 'look',\n 'highly',\n 'her.',\n 'different',\n 'come',\n 'together',\n 'second',\n 'now',\n 'me,',\n 'man',\n 'without',\n 'sure',\n 'real',\n 'publisher',\n 'filled',\n 'definitely',\n 'We',\n 'enough',\n 'before',\n 'yet',\n 'dark',\n 'One',\n \"It's\",\n 'thing',\n 'looking',\n 'him.',\n 'become',\n 'why',\n 'liked',\n 'must',\n 'got',\n 'In',\n 'once',\n 'hard',\n 'enjoyed',\n 'nothing',\n 'keep',\n 'down',\n 'those',\n 'series.',\n \"I've\",\n 'us',\n 'told',\n 'fantastic',\n 'sweet',\n 'fell',\n 'anything',\n 'So',\n '(hide',\n 'interesting',\n 'true',\n 'here',\n 'books.',\n 'strong',\n 'past',\n 'literally',\n 'bit',\n '(view',\n 'knew',\n 'found',\n 'since',\n 'quite',\n 'funny,',\n 'few',\n 'fan',\n 'fall',\n '4',\n 'takes',\n 'such',\n 'stories',\n \"couldn't\",\n 'book!',\n 'same',\n 'long',\n 'left',\n 'cannot',\n 'you,',\n 'love.',\n 'around',\n 'should',\n 'last',\n 'feelings',\n \"I'd\",\n 'seems',\n 'bad',\n 'His',\n 'took',\n 'started',\n 'characters,',\n 'As',\n 'young',\n 'you.',\n 'life,',\n 'heroine',\n 'girl',\n 'end.',\n 'better',\n 'spoiler)[',\n 'review',\n 'comes',\n 'along',\n 'very,',\n 'trying',\n 'seem',\n 'its',\n 'feels',\n 'everyone',\n 'again',\n 'All',\n '5',\n 'stars!!',\n 'stars',\n 'kept',\n 'wants',\n 'steamy',\n 'contemporary',\n 'novel',\n 'meets',\n 'begins',\n 'amazing',\n 'That',\n 'smart',\n 'romance.',\n 'Not',\n 'Her',\n 'work',\n 'whole',\n 'old',\n 'wonderful',\n 'romantic',\n 'job',\n 'hope',\n 'gorgeous',\n 'finally',\n 'all.',\n 'LOVED',\n \"I'll\",\n 'it,',\n 'fast-paced',\n 'care',\n \"that's\",\n 'spoiler)]',\n 'someone',\n 'live',\n \"isn't\",\n 'writes',\n 'turns',\n 'smart,',\n 'having',\n 'getting',\n 'beginning',\n 'woman',\n 'perfectly',\n 'one.',\n 'her,',\n 'against',\n \"you're\",\n 'tell',\n 'seemed',\n 'knows',\n 'high',\n 'able',\n 'THE',\n '3.5',\n '\"You',\n 'start',\n 'school',\n 'forward',\n 'created',\n 'connection',\n 'chemistry',\n 'For',\n 'stay',\n 'stars.',\n 'series,',\n 'herself',\n 'erotic',\n 'conclusion',\n 'When',\n 'These',\n '\"',\n 'top',\n 'fun',\n 'Will',\n 'No',\n 'way.',\n 'supporting',\n 'person',\n 'lost',\n 'friends',\n 'far',\n 'books,',\n 'authors',\n \"author's\",\n 'While',\n 'several',\n 'moments',\n 'memorable',\n 'love,',\n 'fans',\n 'down.',\n 'day',\n 'adored',\n 'NOT',\n 'Favorite',\n '.',\n 'twists',\n 'together.',\n 'them.',\n 'point',\n 'miss',\n 'living',\n 'Just',\n 'ARC',\n 'write',\n \"won't\",\n 'try',\n 'here.',\n 'finished',\n 'Stars!!',\n 'Even',\n 'time.',\n 'readers',\n 'male',\n 'huge',\n 'guy',\n 'enjoy',\n 'during',\n 'Their',\n 'New',\n \"Don't\",\n 'you.\"',\n 'style',\n 'myself',\n 'anyone',\n 'slow',\n 'read,',\n 'plenty',\n 'passionate',\n 'major',\n 'help',\n 'gave',\n 'finds',\n 'course',\n 'Mia',\n 'Alpha',\n 'understand',\n 'sweet,',\n 'stop',\n 'friend',\n 'ends',\n 'deep',\n 'witty',\n 'thinking',\n 'said',\n 'meet',\n 'making',\n 'home',\n 'begin',\n 'already',\n 'adult',\n 'At',\n 'tons',\n \"there's\",\n 'simply',\n 'short',\n 'heart.',\n 'happened',\n 'eyes',\n 'coming',\n 'came',\n 'LOVE',\n 'HOT',\n 'yes,',\n 'worth',\n 'throughout',\n 'story!',\n 'said,',\n 'leave',\n 'learn',\n 'hero',\n 'full',\n 'change',\n 'becomes',\n 'became',\n 'Kristen',\n 'Although',\n 'words',\n 'satisfying',\n 'maybe',\n 'may',\n 'it!',\n 'incredible',\n 'fact',\n 'exchange',\n 'big',\n 'away.',\n 'turn',\n 'total',\n 'talented',\n 'surprising',\n 'storyline',\n 'reader',\n 'painful',\n 'pages',\n 'met',\n 'loving',\n 'lives',\n 'him,',\n 'here,',\n 'happy',\n 'college',\n 'broke',\n 'three',\n 'sometimes',\n \"she's\",\n 'romance,',\n 'probably',\n 'page',\n 'other.',\n 'night',\n 'more.',\n 'matter',\n 'intense',\n 'gives',\n 'feeling',\n 'again.',\n 'With',\n 'Emma',\n 'Ashley',\n '3',\n 'under',\n 'surprised',\n 'review.',\n 'pure',\n 'emotions',\n 'believe',\n 'world.',\n 'time,',\n 'surprise',\n 'side',\n 'place',\n 'humor',\n 'giving',\n 'events',\n 'cast',\n 'VERY',\n 'Some',\n 'Oh',\n 'How',\n 'Also,',\n 'Adam',\n '(and',\n '\"I\\'m',\n 'year',\n 'used',\n 'that,',\n 'movie',\n 'move',\n 'knowing',\n 'inside',\n 'human',\n 'hot,',\n 'goes',\n 'close',\n 'all,',\n \"There's\",\n 'SO',\n 'writer',\n 'went',\n 'truly',\n 'single',\n 'sexual',\n 'parts',\n 'loves',\n 'journey',\n 'hate',\n 'happen',\n 'After',\n 'twist',\n 'tries',\n 'that.',\n 'small',\n 'sees',\n 'interested',\n 'instead',\n 'history',\n 'half',\n 'especially',\n 'else',\n 'easy',\n 'chance',\n 'afraid',\n 'Review',\n '(*ARC',\n 'word',\n 'town',\n 'touch',\n 'too.',\n 'set',\n 'open',\n 'name',\n 'men',\n 'hands',\n 'fucking',\n 'fabulous',\n 'Yes,',\n 'Stars',\n 'MC',\n 'Book',\n '&',\n '\"The',\n 'well.',\n 'thrilled',\n 'soon',\n 'slowly',\n 'show',\n 'sad',\n 'remember',\n 'relationship.',\n 'is.',\n 'important',\n 'immediately',\n 'grew',\n 'follow',\n 'extremely',\n 'early',\n 'deeply',\n 'damaged',\n 'course,',\n 'again,',\n 'action',\n 'Or',\n 'Dean',\n 'women',\n 'steam',\n 'spoilers',\n 'sense',\n 'questions',\n 'must-read',\n 'least',\n 'hold',\n 'head',\n \"he's\",\n 'guess',\n 'group',\n 'gets',\n 'family.',\n 'face',\n 'emotionally',\n 'drawn',\n 'drama',\n 'dialogue',\n 'cover',\n 'complete',\n 'break',\n 'boy',\n 'beautifully',\n 'author.',\n 'amount',\n 'POV',\n 'Nick',\n \"He's\",\n '2',\n \"'The\",\n 'wrong',\n 'turned',\n 'tough',\n 'thrilling',\n 'scenes.',\n 'needed',\n 'mean,',\n 'me.\"',\n 'happens',\n 'exactly',\n 'entire',\n 'before.',\n 'beautiful,',\n 'banter',\n '\"You\\'re',\n 'year.',\n 'well,',\n 'terrible',\n 'star',\n 'stand',\n 'series!',\n 'secrets',\n 'scene',\n 'power',\n 'needs',\n 'in.',\n 'idea',\n 'himself',\n 'glad',\n 'fresh',\n 'fight',\n 'fast-paced,',\n 'certainly',\n 'adore',\n 'Of',\n 'Love',\n 'Logan',\n '\"He',\n 'worked',\n 'unique',\n 'trust',\n 'together,',\n 'tale',\n 'sports',\n 'setting',\n 'second-chance',\n 'realizes',\n 'ready',\n 'quote:',\n 'moment',\n 'lived',\n \"haven't\",\n 'forget',\n 'finish',\n 'enjoyable',\n 'emotion',\n 'done',\n 'describe',\n 'delivers',\n 'creative',\n 'character.',\n 'behind',\n 'attention',\n 'although',\n 'Tate',\n 'Seriously,',\n 'Both',\n 'Because',\n 'AND',\n 'writing.',\n 'voice',\n 'third',\n 'summer',\n 'rest',\n 'reason',\n 'realize',\n 'pain',\n 'out.',\n 'order',\n 'near',\n 'light',\n 'later',\n 'is,',\n 'inner',\n 'future',\n 'family,',\n 'ending.',\n 'earlier',\n 'control',\n 'body',\n 'To',\n 'Once',\n 'James',\n '(I',\n \"wouldn't\",\n 'works',\n 'wild',\n 'up.',\n 'too,',\n 'starts',\n 'sex,',\n 'obsessed',\n 'mostly',\n 'middle',\n 'less',\n 'house',\n 'falling',\n 'ended',\n 'end,',\n 'detail',\n 'couple',\n 'connected',\n 'clear',\n 'changed',\n 'attracted',\n 'alone',\n 'Olivia',\n 'Jake',\n 'Every',\n '**',\n '\"We',\n 'with.',\n 'unforgettable',\n 'ultimately',\n 'suspense',\n 'suddenly',\n 'spoiler)].',\n 'sitting.',\n 'seen',\n 'saw',\n 'quickly',\n 'quick',\n 'present',\n 'play',\n 'modern',\n 'led',\n 'it.\"',\n 'heroine,',\n 'heartbreaking',\n 'given',\n 'fighting',\n 'expect',\n 'doing',\n 'difficult',\n 'debut',\n 'days',\n 'brilliant',\n 'book!!',\n 'admit',\n 'Loved',\n 'From',\n 'BUT',\n 'Another',\n 'well-written',\n 'ways',\n 'waiting',\n 'tells',\n 'stunning',\n 'standalone',\n 'problem',\n 'pick',\n 'page.',\n 'others',\n 'older',\n 'mind',\n 'learned',\n 'fast',\n 'falls',\n 'excited',\n 'engaging',\n 'daughter',\n 'crazy',\n 'classic',\n 'certain',\n 'boyfriend',\n 'age',\n 'Then',\n \"That's\",\n 'Maybe',\n 'Mary',\n 'Kate',\n 'However,',\n 'Do',\n 'Chase',\n 'yourself',\n 'violent',\n 'usually',\n 'tried',\n 'thrown',\n 'there.',\n 'taking',\n 'spend',\n 'soul',\n 'shows',\n 'sensitive',\n 'previous',\n 'original',\n 'mother',\n 'meant',\n 'husband',\n 'however,',\n 'gritty',\n 'graphic',\n 'gifted',\n 'friendship',\n 'follows',\n 'experience',\n 'eventually',\n 'edge',\n 'detailed',\n 'dangerous',\n 'cold',\n 'bring',\n \"She's\",\n 'Jamie',\n 'Jack',\n 'Gabriel',\n 'Full',\n '--',\n 'working',\n 'whether',\n 'wanting',\n 'use',\n 'though,',\n 'struggles',\n 'story!!',\n 'stories.',\n 'stopped',\n 'secret',\n 'reads',\n 'reading.',\n 'rather',\n 'plot.',\n 'please',\n 'nice',\n 'must-read.',\n 'music',\n 'mix',\n 'mention',\n 'means',\n 'keeps',\n 'imagine',\n 'held',\n 'gone',\n 'forced',\n 'first,',\n 'due',\n 'determined',\n 'choices',\n 'basically',\n 'back.',\n 'ago',\n 'absolute',\n 'Scott',\n 'Kennedy',\n 'Ethan',\n 'Elle',\n 'way,',\n 'thrilling,',\n 'taken',\n 'strong,',\n 'spent',\n 'run',\n 'review)',\n 'question',\n 'possibly',\n 'past.',\n 'parents',\n 'often',\n 'minute',\n 'mean',\n 'married',\n 'marriage',\n 'man.',\n \"let's\",\n 'kids',\n 'installment',\n 'hell',\n 'good.',\n 'girls',\n 'game',\n 'fuck',\n 'free',\n 'focus',\n 'father',\n 'dirty',\n 'delicious',\n 'dark,',\n 'called',\n 'brother',\n 'black',\n 'among',\n 'alternating',\n 'added',\n 'across',\n 'Read',\n 'Penelope',\n 'On',\n 'Oh,',\n 'Katy',\n 'Gavin',\n ...]"
     },
     "execution_count": 1666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1667,
   "outputs": [],
   "source": [
    "def vectorize_text(text: Any, label: Any) -> Any:\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Normalizing Data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1668,
   "outputs": [],
   "source": [
    "def normalize_data(x: np.ndarray, y: np.ndarray, batch_size: int = BATCH_SIZE) -> Any:\n",
    "    y = tf.keras.utils.to_categorical(y)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(vectorize_text)\n",
    "    print(dataset)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1669,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(TensorSpec(shape=(None, 250), dtype=tf.int64, name=None), TensorSpec(shape=(None, 6), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = normalize_data(train_dataset['review_text'], train_dataset['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**MLP**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1670,
   "outputs": [],
   "source": [
    "# Define the model\n",
    "mlp = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(MAX_FEATURES, EMBEDDING_DIM),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(CLASSES, activation='sigmoid'),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1671,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_40 (Embedding)    (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " global_average_pooling1d_26  (None, 128)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,565,382\n",
      "Trainable params: 2,565,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1672,
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "mlp.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1673,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6943 - accuracy: 0.2109\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.6925 - accuracy: 0.3730\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6906 - accuracy: 0.4170\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6884 - accuracy: 0.4170\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.6860 - accuracy: 0.4170\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6834 - accuracy: 0.4170\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6809 - accuracy: 0.4170\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.6784 - accuracy: 0.4170\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6758 - accuracy: 0.4170\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.6730 - accuracy: 0.4170\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6701 - accuracy: 0.4170\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.6670 - accuracy: 0.4170\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6638 - accuracy: 0.4170\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6604 - accuracy: 0.4170\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6568 - accuracy: 0.4170\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6531 - accuracy: 0.4170\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.6491 - accuracy: 0.4170\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.6450 - accuracy: 0.4170\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6406 - accuracy: 0.4170\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6361 - accuracy: 0.4170\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6312 - accuracy: 0.4170\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6262 - accuracy: 0.4170\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6209 - accuracy: 0.4170\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6153 - accuracy: 0.4170\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6094 - accuracy: 0.4170\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6033 - accuracy: 0.4170\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.5969 - accuracy: 0.4170\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5902 - accuracy: 0.4170\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5832 - accuracy: 0.4170\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5760 - accuracy: 0.4170\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5685 - accuracy: 0.4170\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.5607 - accuracy: 0.4170\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.5527 - accuracy: 0.4170\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5445 - accuracy: 0.4170\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5360 - accuracy: 0.4170\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5274 - accuracy: 0.4170\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5187 - accuracy: 0.4170\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5098 - accuracy: 0.4170\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5008 - accuracy: 0.4170\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4917 - accuracy: 0.4170\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4827 - accuracy: 0.4170\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4737 - accuracy: 0.4170\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4647 - accuracy: 0.4170\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4558 - accuracy: 0.4170\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4471 - accuracy: 0.4170\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4386 - accuracy: 0.4170\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4304 - accuracy: 0.4170\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4224 - accuracy: 0.4170\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4147 - accuracy: 0.4170\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4073 - accuracy: 0.4170\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4004 - accuracy: 0.4170\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3938 - accuracy: 0.4170\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3876 - accuracy: 0.4170\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3818 - accuracy: 0.4170\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3764 - accuracy: 0.4170\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.3713 - accuracy: 0.4170\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.3666 - accuracy: 0.4170\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3622 - accuracy: 0.4170\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3581 - accuracy: 0.4170\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3544 - accuracy: 0.4170\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3510 - accuracy: 0.4170\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3479 - accuracy: 0.4170\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3451 - accuracy: 0.4170\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3427 - accuracy: 0.4170\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3406 - accuracy: 0.4170\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3387 - accuracy: 0.4170\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3372 - accuracy: 0.6592\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3360 - accuracy: 0.4258\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3350 - accuracy: 0.4209\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3342 - accuracy: 0.4209\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3337 - accuracy: 0.4209\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3333 - accuracy: 0.4209\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3330 - accuracy: 0.4209\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3327 - accuracy: 0.4209\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3324 - accuracy: 0.4209\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3321 - accuracy: 0.4209\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3318 - accuracy: 0.4209\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.3314 - accuracy: 0.4209\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3310 - accuracy: 0.4248\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.3305 - accuracy: 0.5967\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3300 - accuracy: 0.6484\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3294 - accuracy: 0.5518\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3288 - accuracy: 0.4766\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3283 - accuracy: 0.4707\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3278 - accuracy: 0.4639\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.3272 - accuracy: 0.4551\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3268 - accuracy: 0.4561\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3263 - accuracy: 0.4502\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3259 - accuracy: 0.4492\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.3255 - accuracy: 0.4541\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3251 - accuracy: 0.4541\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3246 - accuracy: 0.4609\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3243 - accuracy: 0.4668\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3238 - accuracy: 0.4697\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3235 - accuracy: 0.4727\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.3231 - accuracy: 0.4727\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.3227 - accuracy: 0.4668\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.3223 - accuracy: 0.4727\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.3220 - accuracy: 0.4697\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3217 - accuracy: 0.4678\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1c08cdf8d60>"
     },
     "execution_count": 1673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "mlp.fit(train_dataset,\n",
    "          epochs=EPOCHS,\n",
    "          callbacks=[tf.keras.callbacks.TensorBoard(f\"{TENSORBOARD_LOGS_PATH_ML}\\\\MLP\"\n",
    "                                                    f\"_BS_{BATCH_SIZE}\"\n",
    "                                                    f\"_MAXFEAT_{MAX_FEATURES}\"\n",
    "                                                    f\"_EMBEDDING_{EMBEDDING_DIM}\"\n",
    "                                                    f\"_SEQUENCELEN_{SEQUENCE_LENGTH}\"\n",
    "                                                    f\"_LR_{LEARNING_RATE}\")])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Testing**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1674,
   "outputs": [],
   "source": [
    "test_ratings = np.random.default_rng().integers(0, CLASSES, 478033)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1675,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(TensorSpec(shape=(None, 250), dtype=tf.int64, name=None), TensorSpec(shape=(None, 6), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "test_dataset = normalize_data(test_dataset['review_text'], test_ratings, batch_size=478033)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1676,
   "outputs": [],
   "source": [
    "def testing_model(model, dataset):\n",
    "    for text, label in dataset.take(BATCH_SIZE):\n",
    "        model_predict = model.predict(text)\n",
    "    return model_predict.argmax(axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Submission**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1677,
   "outputs": [],
   "source": [
    "# Submission code\n",
    "sample_submission = pd.read_csv(INPUT_PATH + \"\\\\goodreads_sample_submission.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1678,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14939/14939 [==============================] - 33s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Getting data for csv file\n",
    "sample_submission['rating'] = testing_model(mlp, test_dataset)\n",
    "sample_submission['review_id'] = [data.decode(\"utf-8\") for data in test_review_ids]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1679,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV registered at C:\\Users\\juanm\\OneDrive\\Bureau\\ESGI - Projets\\4IABD\\Projet Deep Learning\\test_juan\\..\\kaggle\\working\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "sample_submission.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"CSV registered at {OUTPUT_PATH}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
